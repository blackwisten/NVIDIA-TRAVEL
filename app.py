import os
import gradio as gr
import requests
from gradio.components import HTML 
import uuid
from PIL import Image
import io
import base64
import random
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_community.retrievers import BM25Retriever
from sklearn.metrics.pairwise import cosine_similarity 
import pickle
import re
import time
import json
import numpy as np
from text2audio.infer import audio2lip
# æ—¥å¿—
from loguru import logger
import datetime
from http import HTTPStatus
from dashscope import Generation
import dashscope
from pydub import AudioSegment
from openai import OpenAI
import requests
import os, re, uuid as _uuid
import html
from urllib.parse import quote
from tavily_mcp_server import TavilyMCPServer
import asyncio
from nat.runtime.loader import load_workflow
from nat.utils.type_utils import StrPath
from dotenv import load_dotenv
from langgraph.checkpoint.memory import InMemorySaver
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent
from datetime import datetime
load_dotenv()

AIQ_WORKFLOW_CFG = os.environ.get(
    "AIQ_WORKFLOW_CFG",
    "/data/lxm/mul-agent/hackathon_aiqtoolkit-main/NeMo-Agent-Toolkit/examples/agents/react/configs/config-reasoning.yml",
)


dashscope.api_key = os.environ.get("dashscope_api_key")
os.environ["amap_key"] = "3cf27a51685ddf02dfb220fe93c036af"
os.environ["AMAP_WEB_KEY"] = "1640e75fcacc07af28cb0a8edd24eaa4"
os.environ["AMAP_JS_SEC"] = "3f96ffb6ef836e956a585f9eee58ee13"
os.environ['TAVILY_API_KEY'] = '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'
os.environ['PEXELS_API_KEY']="ZRRsieLqDKsRxzxNH97mN7NlGgEoIDFSzdYKB42S4Tzfc8BWtVzKpWz3"
PEXELS_API_KEY=os.environ.get("PEXELS_API_KEY")
Weather_APP_KEY = '797ab5e76cdf458b82b1283e100b9a5b'
GAODE_API_KEY=os.environ.get("amap_key")
BAILIAN_API_KEY=os.environ.get("DASHSCOPE_API_KEY", "")
# åˆå§‹åŒ–æ¨¡å‹
qwen_client = OpenAI(
    api_key=os.environ.get("DASHSCOPE_API_KEY", ""),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

client = MultiServerMCPClient(
    {
        "amap-amap-sse": {
            "url": f"https://mcp.amap.com/sse?key={GAODE_API_KEY}",
            "transport": "sse"
        }
    }   # type: ignore
)


llmMCP = ChatOpenAI(
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    model="qwen-plus",
    temperature=0.2,
    api_key=BAILIAN_API_KEY  # type: ignore
    ,streaming=True
)

def aiq_run_workflow(config_file: StrPath, input_str: str) -> str:
    """
    ä»¥â€œåŒæ­¥â€çš„æ–¹å¼è¿è¡Œ NAT å·¥ä½œæµï¼Œæ–¹ä¾¿åœ¨ Gradio çš„æŒ‰é’®ç‚¹å‡»å›è°ƒé‡Œç›´æ¥è°ƒç”¨ã€‚
    """
    async def _go() -> str:
        async with load_workflow(config_file) as workflow:
            async with workflow.run(input_str) as runner:
                return await runner.result(to_type=str)
    # gradio çš„å›è°ƒåœ¨çº¿ç¨‹é‡Œè·‘ï¼Œé€šå¸¸æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œç›´æ¥ asyncio.run å®‰å…¨ç®€æ´
    return asyncio.run(_go())

def process_network_aiq(query: str, cfg_path: str):
    """
    Gradio å›è°ƒï¼šç”¨ AIQ å·¥ä½œæµåšä¸€æ¬¡è”ç½‘æœç´¢ã€‚
    """
    try:
        text = aiq_run_workflow(cfg_path or AIQ_WORKFLOW_CFG, query.strip())
        # å¦‚æœä½ å³ä¾§å·²æœ‰â€œå›¾æ–‡å¡ç‰‡åŒºåŸŸâ€ï¼ˆcards_htmlï¼‰ï¼Œå¯ä»¥æŠŠ text ä¹Ÿå–‚ç»™å®ƒï¼š
        # cards = build_info_cards(query, text)    # ä½ å·²æœ‰è¿™ä¸ªå‡½æ•°
        # return text, cards
        return text
    except Exception as e:
        return f"[AIQ] è¿è¡Œå¤±è´¥ï¼š{e}"


#RAGæ‰€éœ€å‡½æ•°
rerank_path = './model/rerank_model'
rerank_model_name = 'BAAI/bge-reranker-large'

def extract_cities_from_text(text):
    # ä»æ–‡æœ¬ä¸­æå–åŸå¸‚åç§°ï¼Œå‡è®¾ä½¿ç”¨jiebaè¿›è¡Œåˆ†è¯å’Œæå–åœ°å
    import jieba.posseg as pseg
    words = pseg.cut(text)
    cities = [word for word, flag in words if flag == "ns"]
    return cities

def find_pdfs_with_city(cities, pdf_directory):
    matched_pdfs = {}
    for city in cities:
        matched_pdfs[city] = []
        for root, _, files in os.walk(pdf_directory):
            for file in files:
                if file.endswith(".pdf") and city in file:
                    matched_pdfs[city].append(os.path.join(root, file))
    return matched_pdfs

def get_embedding_pdf(text, pdf_directory):
    # ä»æ–‡æœ¬ä¸­æå–åŸå¸‚åç§°
    cities = extract_cities_from_text(text)
    # æ ¹æ®åŸå¸‚åç§°åŒ¹é…PDFæ–‡ä»¶
    city_to_pdfs = find_pdfs_with_city(cities, pdf_directory)
    return city_to_pdfs

def load_rerank_model(model_name=rerank_model_name):
    """
    åŠ è½½é‡æ’åæ¨¡å‹ã€‚
    
    å‚æ•°:
    - model_name (str): æ¨¡å‹çš„åç§°ã€‚é»˜è®¤ä¸º 'BAAI/bge-reranker-large'ã€‚
    
    è¿”å›:
    - FlagReranker å®ä¾‹ã€‚
    
    å¼‚å¸¸:
    - ValueError: å¦‚æœæ¨¡å‹åç§°ä¸åœ¨æ‰¹å‡†çš„æ¨¡å‹åˆ—è¡¨ä¸­ã€‚
    - Exception: å¦‚æœæ¨¡å‹åŠ è½½è¿‡ç¨‹ä¸­å‘ç”Ÿä»»ä½•å…¶ä»–é”™è¯¯ã€‚
    """ 
    if not os.path.exists(rerank_path):
        os.makedirs(rerank_path, exist_ok=True)
    rerank_model_path = os.path.join(rerank_path, model_name.split('/')[1] + '.pkl')
    #print(rerank_model_path)
    logger.info('Loading rerank model...')
    if os.path.exists(rerank_model_path):
        try:
            with open(rerank_model_path , 'rb') as f:
                reranker_model = pickle.load(f)
                logger.info('Rerank model loaded.')
                return reranker_model
        except Exception as e:
            logger.error(f'Failed to load embedding model from {rerank_model_path}') 
    else:
        try:
            os.system('apt install git')
            os.system('apt install git-lfs')
            os.system(f'git clone https://code.openxlab.org.cn/answer-qzd/bge_rerank.git {rerank_path}')
            os.system(f'cd {rerank_path} && git lfs pull')
            
            with open(rerank_model_path , 'rb') as f:
                reranker_model = pickle.load(f)
                logger.info('Rerank model loaded.')
                return reranker_model
                
        except Exception as e:
            logger.error(f'Failed to load rerank model: {e}')

def rerank(reranker, query, contexts, select_num):
    from FlagEmbedding import FlagReranker
    reranker = FlagReranker('/data/lxm/mul-agent/hackathon_aiqtoolkit-main/NVIDIA-TRAVEL/model/rerank_model', use_fp16=True)
    merge = [[query, context] for context in contexts]
    scores = reranker.compute_score(merge)
    sorted_indices = np.argsort(scores)[::-1]

    return [contexts[i] for i in sorted_indices[:select_num]]

def get_embedding_qwen(text):
    response = qwen_client.embeddings.create(
        model="text-embedding-v1",  # DashScope åµŒå…¥æ¨¡å‹
        input=text
    )
    return response.data[0].embedding

def embedding_make(text_input, pdf_directory):

    city_to_pdfs = get_embedding_pdf(text_input, pdf_directory)
    city_list = []
    for city, pdfs in city_to_pdfs.items():
        print(f"City: {city}")
        for pdf in pdfs:
            city_list.append(pdf)
    
    if len(city_list) != 0:
        # all_pdf_pages = []
        all_text = ''
        for city in city_list:
            from pdf_read import FileOperation
            file_opr = FileOperation()
            try:
                text, error = file_opr.read(city)
            except:
                continue
            all_text += text
            
        pattern = re.compile(r'[^\u4e00-\u9fff](\n)[^\u4e00-\u9fff]', re.DOTALL)
        all_text = re.sub(pattern, lambda match: match.group(0).replace('\n', ''), all_text)

        text_spliter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=300) 
        docs = text_spliter.create_documents([all_text])
        splits = text_spliter.split_documents(docs)
        question=text_input
        
        retriever = BM25Retriever.from_documents(splits)
        retriever.k = 20
        bm25_result = retriever.invoke(question)


        question_vector = get_embedding_qwen(question)
        pdf_vector_list = []
        
        start_time = time.perf_counter()

        # em = EmbeddingModel(config)  
        for i in range(len(bm25_result)):
            x = get_embedding_qwen(bm25_result[i].page_content)
            pdf_vector_list.append(x)
            time.sleep(0.65)

        query_embedding = np.array(question_vector)
        query_embedding = query_embedding.reshape(1, -1)

        similarities = cosine_similarity(query_embedding, pdf_vector_list)

        top_k = 10
        top_k_indices = np.argsort(similarities[0])[-top_k:][::-1]

        emb_list = []
        for idx in top_k_indices:
            all_page = splits[idx].page_content
            emb_list.append(all_page)
        print(len(emb_list))

        reranker_model = load_rerank_model()

        documents = rerank(reranker_model, question, emb_list, 3)
        logger.info("After rerank...")
        reranked = []
        for doc in documents:
            reranked.append(doc)
        print(len(reranked))
        reranked = ''.join(reranked)

        model_input = f'ä½ æ˜¯ä¸€ä¸ªæ—…æ¸¸æ”»ç•¥å°åŠ©æ‰‹ï¼Œä½ çš„ä»»åŠ¡æ˜¯ï¼Œæ ¹æ®æ”¶é›†åˆ°çš„ä¿¡æ¯ï¼š\n{reranked}.\næ¥ç²¾å‡†å›ç­”ç”¨æˆ·æ‰€æå‡ºçš„é—®é¢˜ï¼š{question}ã€‚'
        print(reranked)

        resp = qwen_client.chat.completions.create(
            model="qwen-plus",                 # å¯æŒ‰éœ€æ¢æˆ qwen-turbo / qwen2.5 ç³»åˆ—
            messages=[{"role": "user", "content": model_input}],
            temperature=0.5,                   # å›ç­”æ›´ç¨³ä¸€äº›ï¼›éœ€è¦æ›´æ´»æ³¼å¯è°ƒé«˜
            stream=False
        )
        output = resp.choices[0].message.content

        return output
    else:
        return "è¯·åœ¨è¾“å…¥ä¸­æåŠæƒ³è¦å’¨è¯¢çš„åŸå¸‚ï¼"

def process_question(history, use_knowledge_base, question, pdf_directory='./dataset'):
    if use_knowledge_base=='æ˜¯':
        response = embedding_make(question, pdf_directory)
    else:
        response = qwen_client.chat.completions.create(
            model="qwen-plus",
            messages=[{"role": "user", "content": question}],
            temperature=0.7
        ).choices[0].message.content
    
    history.append((question, response))
    return "", history

def clear_history(history):
    history.clear()
    return history

# è·å–åŸå¸‚ä¿¡æ¯-å’Œé£å¤©æ°”API 
def get_location_data(location,api_key):  
    """  
    å‘ QWeather API å‘é€ GET è¯·æ±‚ä»¥è·å–å¤©æ°”æ•°æ®ã€‚  
  
    :param location: åœ°ç‚¹åç§°æˆ–ç»çº¬åº¦ï¼ˆä¾‹å¦‚ï¼š"beijing" æˆ– "116.405285,39.904989"ï¼‰  
    :param api_key: ä½ çš„ QWeather API å¯†é’¥  
    :return: å“åº”çš„ JSON æ•°æ®  
    """  
    # æ„å»ºè¯·æ±‚ URL  
    url = f"https://geoapi.qweather.com/v2/city/lookup?location={location}&key={api_key}"  
  
    # å‘é€ GET è¯·æ±‚  
    response = requests.get(url)  
  
    # æ£€æŸ¥å“åº”çŠ¶æ€ç   
    if response.status_code == 200:  
        # è¿”å› JSON æ•°æ®  
        return response.json()
    else:  
        # å¤„ç†é”™è¯¯æƒ…å†µ  
        print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")  
        print(response.text)  
        return None
    
# è·å–å¤©æ°”-ç©¿æ­æ¨è 
def get_weather_forecast(location_id,api_key):  
    """  
    å‘QWeather APIå‘é€è¯·æ±‚ä»¥è·å–æœªæ¥å‡ å¤©çš„å¤©æ°”é¢„æŠ¥ã€‚  
  
    å‚æ•°:  
    - location: åœ°ç‚¹IDæˆ–ç»çº¬åº¦  
    - api_key: ä½ çš„QWeather APIå¯†é’¥  
    - duration: é¢„æŠ¥çš„æ—¶é•¿ï¼Œ'3d' æˆ– '7d'  
  
    è¿”å›:  
    - å“åº”çš„JSONå†…å®¹  
    """
    
    # æ„å»ºè¯·æ±‚çš„URL  
    url = f"https://devapi.qweather.com/v7/weather/3d?location={location_id}&key={api_key}"  
  
    # å‘é€GETè¯·æ±‚  
    response = requests.get(url)  
  
    # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ  
    if response.status_code == 200:  
        # è¿”å›å“åº”çš„JSONå†…å®¹  
        return response.json()  
    else:  
        # å¦‚æœè¯·æ±‚ä¸æˆåŠŸï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯  
        print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}ï¼Œé”™è¯¯ä¿¡æ¯ï¼š{response.text}")  
        return None  

def style_tags_from_weather(temp_c: float, condition_text: str):
    cond = (condition_text or "").lower()
    season = "spring"; tags = []; note = []
    if temp_c >= 30: season="summer"; tags+=["lightweight","breathable","short-sleeve","linen","cotton"]; note.append("ç‚çƒ­ï¼šæ¸…çˆ½é¢æ–™ã€çŸ­è¢–/çŸ­è£™/çŸ­è£¤")
    elif 20 <= temp_c < 30: season="spring"; tags+=["casual","t-shirt","jeans","sneakers","layering"]; note.append("æ¸©æš–ï¼šTæ¤+è–„å¤–å¥—/é•¿è£™")
    elif 10 <= temp_c < 20: season="fall"; tags+=["jacket","trench coat","sweater","long-sleeve"]; note.append("å¾®å‡‰ï¼šé£è¡£/é’ˆç»‡/è½»è–„å¤–å¥—")
    else: season="winter"; tags+=["down jacket","coat","thermal","scarf","boots"]; note.append("å¯’å†·ï¼šä¿æš–å†…æ­+å¤§è¡£/ç¾½ç»’")
    if ("rain" in cond) or ("é›¨" in cond): tags+=["raincoat","waterproof","hooded","umbrella"]; note.append("æœ‰é›¨ï¼šé˜²æ°´å¤–å¥—/é›¨å…·")
    if ("snow" in cond) or ("é›ª" in cond): tags+=["snow","down","fur collar","boots"]; note.append("æœ‰é›ªï¼šé˜²æ»‘é´+è“¬æ¾å¤–å¥—")
    if ("wind" in cond) or ("é£" in cond): tags+=["windbreaker"]; note.append("æœ‰é£ï¼šé˜²é£å¤–å¥—")
    if ("sunny" in cond) or ("æ™´" in cond): tags+=["sunglasses"]; note.append("æ™´ï¼šæ³¨æ„é˜²æ™’")
    return season, list(dict.fromkeys(tags)), "ï¼›".join(note)

def fetch_pexels_images(query: str, count: int = 8):
    key = os.environ.get("PEXELS_API_KEY", "")
    if not key: 
        print("PEXELS_API_KEY missing"); 
        return []
    try:
        r = requests.get("https://api.pexels.com/v1/search",
                         headers={"Authorization": key},
                         params={"query": query, "per_page": count, "orientation": "portrait"},
                         timeout=10)
        js = r.json(); photos = js.get("photos") or []
        out = []
        for p in photos:
            url = (p.get("src") or {}).get("large") or (p.get("src") or {}).get("medium")
            if url: out.append((url, p.get("alt") or ""))
        print(f"[PEXELS] {query} -> {len(out)}")
        return out
    except Exception as e:
        print("Pexels error:", e)
        return []

def outfit_reco_by_weather(temp_c: float, cond_text: str, city: str=""):
    season, tags, note = style_tags_from_weather(temp_c, cond_text)
    men_q   = f"men {season} outfit lookbook street style {' '.join(tags)}"
    women_q = f"women {season} outfit lookbook street style {' '.join(tags)}"
    men   = fetch_pexels_images(men_q, 8)   or fetch_unsplash_images(men_q, 8)
    women = fetch_pexels_images(women_q, 8) or fetch_unsplash_images(women_q, 8)
    summary = f"{city}å½“å‰ä½“æ„Ÿçº¦ {int(round(temp_c))}â„ƒï¼Œ{cond_text}ã€‚{note}ã€‚"
    return men, women, summary, men_q, women_q

api_key = os.environ.get("api_key")
amap_key = os.environ.get("amap_key")

def get_completion(messages, model="qwen3-max-preview"):
    print(messages)
    response = qwen_client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=0,  # æ¨¡å‹è¾“å‡ºçš„éšæœºæ€§ï¼Œ0 è¡¨ç¤ºéšæœºæ€§æœ€å°
        seed=1024,  # éšæœºç§å­ä¿æŒä¸å˜ï¼Œtemperature å’Œ prompt ä¸å˜çš„æƒ…å†µä¸‹ï¼Œè¾“å‡ºå°±ä¼šä¸å˜
        tool_choice="auto",  # é»˜è®¤å€¼ï¼Œç”±ç³»ç»Ÿè‡ªåŠ¨å†³å®šï¼Œè¿”å›function callè¿˜æ˜¯è¿”å›æ–‡å­—å›å¤
        tools=[{
            "type": "function",
            "function": {

                "name": "get_location_coordinate",
                "description": "æ ¹æ®POIåç§°ï¼Œè·å¾—POIçš„ç»çº¬åº¦åæ ‡",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": {
                            "type": "string",
                            "description": "POIåç§°ï¼Œå¿…é¡»æ˜¯ä¸­æ–‡",
                        },
                        "city": {
                            "type": "string",
                            "description": "POIæ‰€åœ¨çš„åŸå¸‚åï¼Œå¿…é¡»æ˜¯ä¸­æ–‡",
                        }
                    },
                    "required": ["location", "city"],
                }
            }
        },
            {
            "type": "function",
            "function": {
                "name": "search_nearby_pois",
                "description": "æœç´¢ç»™å®šåæ ‡é™„è¿‘çš„poi",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "longitude": {
                            "type": "string",
                            "description": "ä¸­å¿ƒç‚¹çš„ç»åº¦",
                        },
                        "latitude": {
                            "type": "string",
                            "description": "ä¸­å¿ƒç‚¹çš„çº¬åº¦",
                        },
                        "keyword": {
                            "type": "string",
                            "description": "ç›®æ ‡poiçš„å…³é”®å­—",
                        }
                    },
                    "required": ["longitude", "latitude", "keyword"],
                }
            }
        }],
    )
    return response.choices[0].message

def extract_route_json(llm_text: str):
    # 1) è§„èŒƒåŒ–å¸¸è§ä¸­æ–‡ç¬¦å·ä¸å¼•å·
    txt = (llm_text or "").strip()
    trans = str.maketrans({
        "â€œ": '"', "â€": '"', "â€˜": "'", "â€™": "'",
        "ï¼š": ":", "ï¼Œ": ",", "ï¼ˆ": "(", "ï¼‰": ")"
    })
    txt = txt.translate(trans)
    # å»æ‰ä»£ç å›´æ 
    # txt = re.sub(r"```[\s\S]*?```", "", txt)
    txt = re.sub(r"```(?:json|JSON)?\s*", "", txt)  # åˆ é™¤å¼€å¤´çš„ ``` æˆ– ```json
    txt = txt.replace("```", "")                    # åˆ é™¤ç»“å°¾çš„ ```

    # 2) æ‰¾åˆ°æœ€åä¸€ä¸ª "route"/'route'
    idx = max(txt.rfind('"route"'), txt.rfind("'route'"))
    if idx == -1:
        return None

    # 3) å‘å·¦æ‰¾æœ€è¿‘çš„ '{' ä½œä¸º JSON å¼€å§‹
    start = txt.rfind("{", 0, idx)
    if start == -1:
        return None

    # 4) ä» start å¼€å§‹åšèŠ±æ‹¬å·é…å¯¹ï¼Œæ‰¾åˆ°æ”¶å°¾
    depth = 0
    end = None
    for i, ch in enumerate(txt[start:], start=start):
        if ch == "{":
            depth += 1
        elif ch == "}":
            depth -= 1
            if depth == 0:
                end = i + 1
                break
    if end is None:
        return None

    blob = txt[start:end]

    # 5) å®½æ¾ä¿®å¤ï¼šå•å¼•å·â†’åŒå¼•å·ï¼›å»æ‰å¯¹è±¡/æ•°ç»„æ”¶å°¾å¤šä½™é€—å·
    blob2 = re.sub(r"'", '"', blob)
    blob2 = re.sub(r",\s*([}\]])", r"\1", blob2)

    try:
        data = json.loads(blob2)
        return data.get("route")
    except Exception as e:
        print("JSON parse failed:", e, "\nblob2=", blob2)
        return None

def _amap_geocode_one(stop: str, city: str, key: str):
    """ä¼˜å…ˆ v5 place/textï¼ˆé™åŸå¸‚ï¼‰â†’ é€€å› v3 geocode/geo â†’ å†ç”¨ v5 å…¨ç½‘æœ"""
    # 1) v5 place/textï¼ˆé™å®šåŸå¸‚ï¼Œæé«˜å‘½ä¸­å’Œç›¸å…³æ€§ï¼‰
    try:
        url1 = (
            "https://restapi.amap.com/v5/place/text?"
            f"key={key}&keywords={quote(stop)}&region={quote(city)}"
            "&city_limit=true&sortrule=weight&page_size=1"
        )
        r1 = requests.get(url1, timeout=5).json()
        pois = (r1 or {}).get("pois") or []
        if pois and pois[0].get("location"):
            return pois[0]["location"]
    except Exception:
        pass

    # 2) v3 geocode/geoï¼ˆåœ°å€è§£æå¸¸å¯¹â€œè·¯/ç«™/å·â€æ›´ç¨³ï¼‰
    try:
        url2 = (
            "https://restapi.amap.com/v3/geocode/geo?"
            f"key={key}&address={quote(stop)}&city={quote(city)}"
        )
        r2 = requests.get(url2, timeout=5).json()
        geos = (r2 or {}).get("geocodes") or []
        if geos and geos[0].get("location"):
            return geos[0]["location"]
    except Exception:
        pass

    # 3) v5 place/textï¼ˆä¸é™å®šåŸå¸‚å…œåº•ï¼‰
    try:
        url3 = (
            "https://restapi.amap.com/v5/place/text?"
            f"key={key}&keywords={quote(stop)}&page_size=1&sortrule=weight"
        )
        r3 = requests.get(url3, timeout=5).json()
        pois = (r3 or {}).get("pois") or []
        if pois and pois[0].get("location"):
            return pois[0]["location"]
    except Exception:
        pass

    return None

# â€”â€” æŠŠæ¯å¤©çš„ stops åšåœ°ç†ç¼–ç ï¼ˆç”¨ä½ å·²æœ‰çš„ get_location_coordinateï¼‰
def geocode_stops(route_list, default_city: str):
    key = os.environ.get("amap_key", "")
    coords = []
    seen = set()
    for day in route_list:
        city = (day.get("city") or default_city or "").strip()
        for stop in day.get("stops", []):
            loc = _amap_geocode_one(stop, city, key)
            print("GEOCODE:", city, stop, "->", loc)
            if loc:
                try:
                    lng, lat = loc.split(",")
                    lng_f, lat_f = float(lng), float(lat)
                    sig = f"{lng_f:.6f},{lat_f:.6f}"
                    if sig not in seen:
                        seen.add(sig)
                        coords.append((lng_f, lat_f, stop))  # âœ… ç»Ÿä¸€ä¸‰å…ƒç»„
                except Exception:
                    continue
    # é˜² URL è¿‡é•¿ï¼Œå…ˆé™åˆ¶ 25 ä¸ªç‚¹
    return coords[:25]

def geocode_stops_by_day(route_list, default_city: str, per_day_limit: int = 12):
    key = os.environ.get("amap_key", "")
    day_points = []  # [{"day":"Day1","points":[(lng,lat,name), ...]}, ...]
    for day in route_list:
        city = (day.get("city") or default_city or "").strip()
        pts = []
        seen = set()
        for stop in day.get("stops", [])[:per_day_limit]:
            loc = _amap_geocode_one(stop, city, key)
            print("GEOCODE-DAY:", day.get("day"), city, stop, "->", loc)
            if not loc:
                continue
            try:
                lng, lat = map(float, loc.split(","))
                sig = f"{lng:.6f},{lat:.6f}"
                if sig not in seen:
                    seen.add(sig)
                    pts.append((lng, lat, stop))
            except Exception:
                continue
        day_points.append({"day": day.get("day") or "", "points": pts})
    return day_points

# â€”â€” ç”Ÿæˆé«˜å¾·é™æ€åœ°å›¾ URLï¼ˆç”»ç‚¹ + æŠ˜çº¿è·¯å¾„ï¼‰
def build_amap_staticmap(points):
    if not points:
        return None

    # âœ… å½’ä¸€åŒ–ï¼š[(lng,lat)] æˆ– [(lng,lat,name)] éƒ½èƒ½å¤„ç†
    norm = []
    for p in points:
        try:
            if len(p) == 2:
                lng, lat = p
                name = ""
            else:
                lng, lat, name = p[0], p[1], p[2]
            norm.append((float(lng), float(lat), name))
        except Exception:
            continue
    points = norm
    if not points:
        return None

    key = os.environ.get("amap_key", "")
    base = "https://restapi.amap.com/v3/staticmap"
    size = "1024*512"

    marker_parts = [f"mid,0xFF0000,{i+1}:{lng},{lat}" for i, (lng, lat, _) in enumerate(points)]
    markers = "|".join(marker_parts)

    path_points = ";".join([f"{lng},{lat}" for (lng, lat, _) in points])
    path = f"weight:5|color:0x0066FF|:{path_points}"

    url = f"{base}?key={key}&size={size}&markers={quote(markers)}&path={quote(path)}"
    print("STATICMAP URL:", url[:200], "...")
    return url

def build_amap_html_for_one_day_interactive(points, day_title="Day", color="#0066FF", zoom=12, height=420):
    # å½’ä¸€åŒ–
    pts = []
    for it in (points or []):
        try:
            lng = float(it[0]); lat = float(it[1])
            name = str(it[2]) if len(it) >= 3 else ""
            pts.append([lng, lat, name])
        except Exception:
            continue
    if not pts:
        return f'<div style="color:#888">{day_title}ï¼šæ²¡æœ‰å¯ç»˜åˆ¶çš„ç‚¹</div>'

    # ä¸­å¿ƒä¸è·¯å¾„
    clng = sum(p[0] for p in pts)/len(pts)
    clat = sum(p[1] for p in pts)/len(pts)
    path = [[p[0], p[1]] for p in pts]

    # ç”¨ Web ç«¯ JS Keyï¼ˆå¹¶å¯æ³¨å…¥å®‰å…¨å¯†é’¥ï¼‰
    js_key = os.environ.get("AMAP_WEB_KEY", os.environ.get("amap_key", ""))
    js_sec = os.environ.get("AMAP_JS_SEC", "")
    sec_snippet = f"window._AMapSecurityConfig={{securityJsCode:'{js_sec}'}};" if js_sec else ""

    # ç”¨ srcdocï¼ˆä¸æ˜¯ data:ï¼‰ï¼Œå¹¶é€šè¿‡ onload å†åˆ›å»ºåœ°å›¾ï¼Œç¡®ä¿ AMap å·²å®šä¹‰
    inner_html = f"""<!doctype html><html><head><meta charset="utf-8"/>
<style>html,body,#map{{height:100%;margin:0;padding:0}}</style></head><body>
<div id="map"></div>
<script>
  window.onerror = function(msg) {{
    document.body.insertAdjacentHTML('afterbegin','<pre style="color:red">'+msg+'</pre>');
  }};
  (function(){{
    {sec_snippet}
    var s = document.createElement('script');
    s.src = 'https://webapi.amap.com/maps?v=2.0&key={js_key}';
    s.async = true;
    s.onload = function(){{
      if (!window.AMap) {{
        document.body.insertAdjacentHTML('afterbegin','<pre style="color:red">AMap still undefined after load</pre>');
        return;
      }}
      var map = new AMap.Map('map', {{ zoom: {zoom}, center: [{clng}, {clat}] }});
      var path = {json.dumps(path)};
      var polyline = new AMap.Polyline({{
        path: path, showDir: true, strokeColor: '{color}', strokeWeight: 5, lineJoin: 'round'
      }});
      map.add(polyline);
      for (var i=0;i<path.length;i++) {{
        new AMap.Marker({{ position: path[i], label: {{ content: String(i+1), direction: 'top' }} }}).setMap(map);
      }}
      map.setFitView();
    }};
    s.onerror = function(){{
      document.body.insertAdjacentHTML('afterbegin','<pre style="color:red">Failed to load AMap JS</pre>');
    }};
    document.head.appendChild(s);
  }})();
</script>
</body></html>"""

    return f'''
<div style="border:1px solid #eee;border-radius:10px;padding:8px">
  <div style="font-weight:600;margin:6px 4px">{day_title}</div>
  <iframe srcdoc="{html.escape(inner_html)}"
          style="width:100%;height:{height}px;border:0;border-radius:8px"></iframe>
</div>
'''

def build_multiday_amap_html_interactive(day_points):
    palette = ["#E74C3C","#3498DB","#2ECC71","#F1C40F","#9B59B6","#1ABC9C","#E67E22","#2C3E50"]
    parts = ['<div style="display:flex;flex-direction:column;gap:16px">']
    any_img = False
    for i, d in enumerate(day_points):
        pts = d.get("points") or []
        day = d.get("day") or f"Day{i+1}"
        html_one = build_amap_html_for_one_day_interactive(
            pts, day_title=day, color=palette[i % len(palette)], zoom=12, height=420
        )
        parts.append(html_one); any_img = True
    parts.append("</div>")
    return "".join(parts) if any_img else "<div style='color:#888'>æ²¡æœ‰å¯ç»˜åˆ¶çš„æ¯æ—¥è·¯çº¿ã€‚</div>"

def get_location_coordinate(location, city):
    url = f"https://restapi.amap.com/v5/place/text?key={amap_key}&keywords={location}&region={city}"
    print(url)
    r = requests.get(url)
    result = r.json()
    if "pois" in result and result["pois"]:
        return result["pois"][0]
    return None

def search_nearby_pois(longitude, latitude, keyword):
    url = f"https://restapi.amap.com/v5/place/around?key={amap_key}&keywords={keyword}&location={longitude},{latitude}"
    print(url)
    r = requests.get(url)
    result = r.json()
    ans = ""
    if "pois" in result and result["pois"]:
        for i in range(min(3, len(result["pois"]))):
            name = result["pois"][i]["name"]
            address = result["pois"][i]["address"]
            distance = result["pois"][i]["distance"]
            ans += f"{name}\n{address}\nè·ç¦»ï¼š{distance}ç±³\n\n"
    return ans

def process_request(prompt):
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåœ°å›¾é€šï¼Œä½ å¯ä»¥æ‰¾åˆ°ä»»ä½•åœ°å€ã€‚"},
        {"role": "user", "content": prompt}
    ]
    response = get_completion(messages)
    if (response.content is None):  # è§£å†³ OpenAI çš„ä¸€ä¸ª 400 bug
        response.content = ""
    messages.append(response)  # æŠŠå¤§æ¨¡å‹çš„å›å¤åŠ å…¥åˆ°å¯¹è¯ä¸­
    print("=====GPTå›å¤=====")
    print(response)
    
    # å¦‚æœè¿”å›çš„æ˜¯å‡½æ•°è°ƒç”¨ç»“æœï¼Œåˆ™æ‰“å°å‡ºæ¥
    while (response.tool_calls is not None):
        # 1106 ç‰ˆæ–°æ¨¡å‹æ”¯æŒä¸€æ¬¡è¿”å›å¤šä¸ªå‡½æ•°è°ƒç”¨è¯·æ±‚
        for tool_call in response.tool_calls:
            args = json.loads(tool_call.function.arguments)
            print(args)
    
            if (tool_call.function.name == "get_location_coordinate"):
                print("Call: get_location_coordinate")
                result = get_location_coordinate(**args)
            elif (tool_call.function.name == "search_nearby_pois"):
                print("Call: search_nearby_pois")
                result = search_nearby_pois(**args)
    
            print("=====å‡½æ•°è¿”å›=====")
            print(result)
    
            messages.append({
                "tool_call_id": tool_call.id,  # ç”¨äºæ ‡è¯†å‡½æ•°è°ƒç”¨çš„ ID
                "role": "tool",
                "name": tool_call.function.name,
                "content": str(result)  # æ•°å€¼result å¿…é¡»è½¬æˆå­—ç¬¦ä¸²
            })
    
        response = get_completion(messages)
        if (response.content is None):  # è§£å†³ OpenAI çš„ä¸€ä¸ª 400 bug
            response.content = ""
        messages.append(response)  # æŠŠå¤§æ¨¡å‹çš„å›å¤åŠ å…¥åˆ°å¯¹è¯ä¸­
    
    print("=====æœ€ç»ˆå›å¤=====")
    print(response.content)
    return response.content

def llm(query, history=[], user_stop_words=[]):
    try:
        messages = [{'role': 'system', 'content': 'You are a helpful assistant.'}]
        for hist in history:
            messages.append({'role': 'user', 'content': hist[0]})
            messages.append({'role': 'assistant', 'content': hist[1]})
        messages.append({'role': 'user', 'content': query})

        response = qwen_client.chat.completions.create(
            model = "qwen3-max-preview",  # æˆ– qwen-turbo
            messages = messages,
            temperature = 0.7,
            stream = True
        )
        content = ""
        for chunk in response:
            if chunk.choices[0].delta.content:
                content += chunk.choices[0].delta.content
        
        return content
    except Exception as e:
        return str(e)

class TavilyMCPTool:
    """
    é€‚é…å™¨ï¼šè®© tavily_mcp_server çš„æœç´¢èƒ½åŠ›ï¼Œå‘ˆç°ä¸ºä¸ LangChain Tool ç›¸åŒçš„æ¥å£
    ï¼ˆæ‹¥æœ‰ name/description/args/invokeï¼‰ï¼Œä»¥ä¾¿è¢«ä½ ç°æœ‰çš„ agent æ‰§è¡Œå™¨å¤ç”¨ã€‚
    """
    def __init__(self, max_results: int = 5, description: str = ""):
        self._server = TavilyMCPServer()  # ç›´æ¥åŒè¿›ç¨‹å¤ç”¨ï¼Œä¸èµ° stdio
        self.name = "tavily_search"       # ä¸ MCP ä¸­å®šä¹‰çš„å·¥å…·åä¿æŒä¸€è‡´
        self.description = description or "åŸºäº Tavily çš„å®æ—¶ç½‘ç»œæœç´¢ï¼ˆMCPï¼‰ã€‚"
        self.args: Dict[str, Dict[str, Any]] = {
            "query": {"type": "string", "description": "æœç´¢æŸ¥è¯¢è¯"},
            "max_results": {"type": "integer", "description": "è¿”å›æ¡æ•°", "default": max_results},
        }
        self._default_max_results = max_results

    def invoke(self, input: str) -> str:
        """
        ä½ çš„ agent æ¡†æ¶ä¼šæŠŠ JSON å­—ç¬¦ä¸²å–‚ç»™è¿™é‡Œï¼›æˆ‘ä»¬è§£æåï¼Œè°ƒç”¨ MCP çš„ _tavily_searchã€‚
        è¿”å›å€¼ï¼šå­—ç¬¦ä¸²ï¼ˆä¿æŒä¸åŸå·¥å…·ä¸€è‡´ï¼‰
        """
        try:
            payload = json.loads(input) if isinstance(input, str) else (input or {})
            query = payload.get("query", "").strip()
            max_results = int(payload.get("max_results", self._default_max_results))
            if not query:
                return "Error: query is required"

            # tavily_mcp_server._tavily_search æ˜¯ä¸€ä¸ª async å‡½æ•°ï¼Œè¿™é‡ŒåŒæ­¥è·‘ä¸€ä¸‹
            result_list = asyncio.run(self._server._tavily_search({"query": query, "max_results": max_results}))

            # _tavily_search è¿”å› List[TextContent]ï¼Œæˆ‘ä»¬æŠŠå®ƒåºåˆ—åŒ–æˆå­—ç¬¦ä¸²
            # æ¯ä¸ª TextContent é‡Œ text æ˜¯ä¸€ä¸ª JSONï¼ˆsummary+resultsï¼‰
            texts: List[str] = []
            for item in result_list:
                # item.type == "text"; item.text æ˜¯ JSON å­—ç¬¦ä¸²
                texts.append(item.text)
            return "\n".join(texts) if texts else "No result."
        except Exception as e:
            return f"[TavilyMCPTool] è°ƒç”¨å¤±è´¥: {e}"

import os, re, requests, html, json
from urllib.parse import quote

# â€”â€” ç¯å¢ƒå˜é‡ï¼ˆæŒ‰ä½ å®é™… key åç§°æ”¹ï¼‰â€”â€”
AMAP_KEY = os.environ.get("amap_key", "")           # ä½ å·²æœ‰çš„é«˜å¾·æœåŠ¡ç«¯ key
PEXELS_KEY = os.environ.get("PEXELS_API_KEY", "")   # å¯é€‰ï¼šPexels å›¾ç‰‡
# ==== å¸¸è§æ™¯ç‚¹åˆ«åï¼ˆå¯é€æ­¥æ‰©å……ï¼‰====
ENTITY_ALIASES = {
    "ç§¦å§‹çš‡å…µé©¬ä¿‘": [
        "ç§¦å§‹çš‡å…µé©¬ä¿‘", "å…µé©¬ä¿‘", "ç§¦å§‹çš‡é™µåšç‰©é™¢", "ç§¦å§‹çš‡å¸é™µåšç‰©é™¢",
        "ç§¦å§‹çš‡é™µ", "Emperor Qinshihuang's Mausoleum Site Museum",
        "Terracotta Army", "Terracotta Warriors and Horses"
    ],
    "æ•…å®«": [
        "æ•…å®«", "åŒ—äº¬æ•…å®«", "æ•…å®«åšç‰©é™¢", "The Palace Museum", "Forbidden City"
    ],
    "ä¸Šæµ·è¿ªå£«å°¼": [
        "ä¸Šæµ·è¿ªå£«å°¼", "ä¸Šæµ·è¿ªå£«å°¼ä¹å›­", "Shanghai Disneyland"
    ],
    "é»„å±±": [
        "é»„å±±", "é»„å±±é£æ™¯åŒº", "Huangshan"
    ],
}

def _normalize_question(q: str):
    q = (q or "").strip()
    # å»æ‰å¸¸è§ä¿®é¥°è¯
    q = re.sub(r"(å¼€æ”¾æ—¶é—´|è¥ä¸šæ—¶é—´|é—¨ç¥¨|ç¥¨ä»·|é—¨ç¥¨ä»·æ ¼|é¢„çº¦|æ”»ç•¥|åœ°å€|æ€ä¹ˆå»|ä»‹ç»|ç®€ä»‹|å¥½ç©å—|å‡ ç‚¹å…³é—¨|æœ€ä½³æ—¶é—´|äº¤é€š|å¼€æ”¾æ—¥|è¥ä¸š|å‚è§‚|é¡»çŸ¥)", "", q)
    q = re.sub(r"[?ï¼Ÿã€ï¼Œã€‚ï¼!ï¼š:ï¼ˆï¼‰()ã€Šã€‹â€œâ€\"']", "", q).strip()
    return q

def extract_entity_and_city(question: str):
    """
    æ›´é²æ£’çš„å®ä½“/åŸå¸‚æŠ½å–ï¼šä¿ç•™æ™¯ç‚¹åï¼Œå¹¶åŸºäºåˆ«åè¡¨äº§å‡ºå€™é€‰åç§°ï¼ˆä¸­æ–‡+è‹±æ–‡ï¼‰
    """
    q = _normalize_question(question)

    # åŸå¸‚/åŒºåŸŸï¼ˆå¯é€‰ï¼‰
    city = ""
    m = re.search(r"([\u4e00-\u9fa5]{2,})å¸‚", question or "")
    if m: city = m.group(1)
    else:
        m2 = re.search(r"(.+?)(?:é™„è¿‘|å‘¨è¾¹)", question or "")
        if m2: city = m2.group(1).strip().rstrip("çš„")

    # åŸºäºåˆ«åè¡¨å¿«é€Ÿå‘½ä¸­
    aliases = []
    for key, names in ENTITY_ALIASES.items():
        if any(n in q for n in names):
            aliases = names[:]   # å‘½ä¸­ä¸€ç±»åˆ«å
            break

    # æ²¡å‘½ä¸­åˆ«åè¡¨ï¼Œåˆ™æŠŠ q è‡ªèº«ä½œä¸ºå€™é€‰
    if not aliases:
        aliases = [q]

    # è¿½åŠ ä¸€ä¸ªæ›´å®˜æ–¹çš„è‹±æ–‡åï¼ˆè‹¥å­˜åœ¨ï¼‰
    # å·²åœ¨åˆ«åè¡¨è¦†ç›–å¸¸è§é¡¹ï¼Œæœªè¦†ç›–å¯è‡ªè¡Œè¿½åŠ 
    return aliases, city

def parse_open_hours_from_text(text: str):
    """
    ä»è”ç½‘æœç´¢çš„æ–‡æœ¬é‡Œå°½å¯èƒ½è§£æå¼€æ”¾æ—¶é—´ã€é—­é¦†æ—¥ç­‰ã€‚
    è¿”å›ï¼š{"hours": [...], "closed": "..."}  éƒ½æ˜¯å­—ç¬¦ä¸²ï¼Œä¾¿äºç›´æ¥å±•ç¤º
    """
    text = (text or "").strip()
    hours = []

    # æ—ºå­£/æ·¡å­£ï¼ˆå¸¸è§å†™æ³•ï¼‰
    m = re.findall(r"(æ—ºå­£|æ·¡å­£)[ï¼š: ]*([^ï¼Œã€‚ï¼›\n]+)", text)
    for tag, val in m:
        hours.append(f"{tag}ï¼š{val.strip()}")

    # é€šç”¨æ—¶é—´æ®µ 08:30-16:30 ç­‰
    m2 = re.findall(r"(\d{1,2}[:ï¼š]\d{2}\s*[-â€”â€“]\s*\d{1,2}[:ï¼š]\d{2})", text)
    for t in m2:
        if t not in hours:
            hours.append(t.replace("ï¼š", ":").replace("â€”", "-").replace("â€“", "-"))

    # åœæ­¢å”®ç¥¨/å…¥åœº
    m3 = re.findall(r"(åœæ­¢(å”®ç¥¨|å…¥åœº)[ï¼š: ]*\d{1,2}[:ï¼š]\d{2})", text)
    for full,_ in m3:
        if full not in hours:
            hours.append(full.replace("ï¼š", ":"))

    # æ¯å‘¨é—­é¦†/å‘¨ä¸€é—­é¦†
    closed = ""
    m4 = re.search(r"(æ¯å‘¨[^ï¼Œã€‚ï¼›\n]*é—­é¦†|å‘¨[ä¸€äºŒä¸‰å››äº”å…­æ—¥å¤©]é—­é¦†)", text)
    if m4:
        closed = m4.group(1).strip()

    return {"hours": hours, "closed": closed}

def _amap_uri_marker(lnglat: str, name: str = ""):
    # lnglat: "lng,lat"
    try:
        lng, lat = lnglat.split(",")
        return f"https://uri.amap.com/marker?position={lng},{lat}&name={quote(name or '')}"
    except Exception:
        return ""

def render_cards_html(entity_name: str, poi: dict, detail: dict, images: list, summary: str, openinfo: dict):
    name = poi.get("name") or detail.get("name") or entity_name
    addr = poi.get("address") or detail.get("address") or ""
    tel  = detail.get("tel") or detail.get("telephone") or ""
    rating = detail.get("rating") or (detail.get("biz_ext") or {}).get("rating") or ""
    price  = (detail.get("biz_ext") or {}).get("cost") or ""
    opentime = detail.get("opentime") or (detail.get("biz_ext") or {}).get("opentime") or ""
    website = (detail.get("website") or detail.get("url") or "").strip()
    lnglat  = poi.get("location") or detail.get("location") or ""
    amap_link = _amap_uri_marker(lnglat, name) if lnglat else ""

    # æŠŠâ€œå³ä¾§æœç´¢ç»“æœâ€è§£æåˆ°çš„å¼€æ”¾æ—¶é—´ä¹Ÿåˆå¹¶å±•ç¤º
    hours_lines = []
    if openinfo.get("hours"):
        hours_lines += openinfo["hours"]
    if opentime and opentime not in hours_lines:
        hours_lines.append(opentime)
    closed_line = openinfo.get("closed", "")

    styles = """
    <style>
    .grid{display:grid;grid-template-columns:repeat(auto-fill,minmax(260px,1fr));gap:14px}
    .card{border:1px solid #eee;border-radius:12px;overflow:hidden;background:#fff}
    .card img{width:100%;height:150px;object-fit:cover}
    .p{padding:12px}
    .title{font-weight:700;font-size:16px;margin-bottom:6px}
    .meta{font-size:13px;color:#555;line-height:1.6;margin-top:6px}
    .btns a{display:inline-block;margin-right:8px;margin-top:8px;padding:6px 10px;border:1px solid #ddd;border-radius:8px;font-size:12px;color:#333;text-decoration:none}
    </style>
    """

    cover = images[0] if images else ""
    bullets = []

    if addr:   bullets.append(f"<div class='meta'>ğŸ“ åœ°å€ï¼š{html.escape(addr)}</div>")
    if hours_lines:
        bullets.append("<div class='meta'>ğŸ•˜ å¼€æ”¾ï¼š<br>"+ "<br>".join(html.escape(x) for x in hours_lines[:4]) + "</div>")
    if closed_line: bullets.append(f"<div class='meta'>ğŸšª é—­é¦†ï¼š{html.escape(closed_line)}</div>")
    if price:  bullets.append(f"<div class='meta'>ğŸ’³ ç¥¨ä»·ï¼š{html.escape(str(price))}</div>")
    if rating: bullets.append(f"<div class='meta'>â­ è¯„åˆ†ï¼š{html.escape(str(rating))}</div>")

    btns = []
    if amap_link: btns.append(f"<a target='_blank' href='{html.escape(amap_link)}'>ğŸ“± æ‰“å¼€é«˜å¾·åœ°å›¾</a>")
    if website:   btns.append(f"<a target='_blank' href='{html.escape(website)}'>ğŸ”— å®˜ç½‘/è¯¦æƒ…</a>")

    main = f"""
    <div class="card">
      {"<img src='"+html.escape(cover)+"'/>" if cover else ""}
      <div class="p">
        <div class="title">{html.escape(name)}</div>
        {"<div class='meta' style='-webkit-line-clamp:4;display:-webkit-box;-webkit-box-orient:vertical;overflow:hidden;'>"+html.escape(summary)+"</div>" if summary else ""}
        {''.join(bullets)}
        {"<div class='btns'>" + "".join(btns) + "</div>" if btns else ""}
      </div>
    </div>
    """

    # æ›´å¤šå›¾ç‰‡
    more = ""
    if len(images) > 1:
        thumbs = []
        for u in images[1:4]:
            thumbs.append(f"<div class='card'><img src='{html.escape(u)}'/></div>")
        more = "".join(thumbs)

    return styles + f"<div class='grid'>{main}{more}</div>"

def amap_search_one(keyword: str, region: str = ""):
    if not AMAP_KEY or not keyword:
        return None
    try:
        r = requests.get(
            "https://restapi.amap.com/v5/place/text",
            params={"key": AMAP_KEY, "keywords": keyword, "region": region, "page_size": 1},
            timeout=6
        ).json()
        pois = (r or {}).get("pois") or []
        return pois[0] if pois else None
    except Exception:
        return None

def amap_detail(poi_id: str):
    if not AMAP_KEY or not poi_id:
        return {}
    try:
        r = requests.get(
            "https://restapi.amap.com/v5/place/detail",
            params={"key": AMAP_KEY, "id": poi_id},
            timeout=6
        ).json()
        return (r or {}).get("pois", [{}])[0] if r else {}
    except Exception:
        return {}

def wiki_fetch(title: str):
    for lang in ["zh", "en"]:
        try:
            r = requests.get(
                f"https://{lang}.wikipedia.org/api/rest_v1/page/summary/{quote(title)}",
                timeout=6
            ).json()
            if not r: continue
            summary = r.get("extract") or ""
            images = []
            if r.get("originalimage", {}).get("source"):
                images.append(r["originalimage"]["source"])
            elif r.get("thumbnail", {}).get("source"):
                images.append(r["thumbnail"]["source"])
            return summary, images
        except Exception:
            continue
    return "", []

def commons_images(query: str, count: int = 4):
    try:
        r = requests.get(
            "https://commons.wikimedia.org/w/api.php",
            params={
                "action": "query","format": "json",
                "generator": "search","gsrsearch": query,"gsrlimit": count*2,
                "prop": "imageinfo","iiprop": "url","iiurlwidth": 1280,"origin": "*",
            }, timeout=6,
        ).json()
        pages = (r or {}).get("query", {}).get("pages", {}) or {}
        urls = []
        for _, p in pages.items():
            ii = (p.get("imageinfo") or [])
            if not ii: continue
            u = ii[0].get("thumburl") or ii[0].get("url")
            if u: urls.append(u)
        uniq, seen = [], set()
        for u in urls:
            if u not in seen:
                uniq.append(u); seen.add(u)
        return uniq[:count]
    except Exception:
        return []

def build_info_cards(query_text: str, search_text: str):
    aliases, city = extract_entity_and_city(query_text)  # å¤šä¸ªå€™é€‰åï¼ˆå«è‹±æ–‡/åˆ«åï¼‰

    # 1) å…ˆç”¨å€™é€‰åæœ POIï¼ˆå‘½ä¸­ç‡é«˜ï¼‰ï¼Œæ‹¿ ID/åæ ‡/åœ°å€
    poi = None
    for kw in aliases:
        poi = amap_search_one(kw, region=city)
        if poi: break
    if not poi:
        # å®åœ¨æ²¡æœ‰ï¼Œç”¨ç¬¬ä¸€ä¸ªåˆ«åå ä½ï¼ˆå¡ç‰‡ä»å¯å±•ç¤ºç®€ä»‹+å›¾ç‰‡ï¼‰
        poi = {"name": aliases[0]}

    detail = amap_detail(poi.get("id","")) if poi.get("id") else {}

    # 2) å–ç®€ä»‹ + å›¾ç‰‡ï¼ˆæŒ‰å€™é€‰åè½®è¯¢ï¼Œç›´åˆ°æ‹¿åˆ°å›¾æˆ–ç®€ä»‹ï¼‰
    summary, imgs = "", []
    for kw in aliases + [poi.get("name","")]:
        if kw:
            s, im = wiki_fetch(kw)
            if s and not summary: summary = s
            if im: imgs += im
        if len(imgs) >= 3 and summary:
            break

    # 3) ç”¨ Commons å†è¡¥å›¾ï¼ˆæŒ‰å€™é€‰åè½®è¯¢ï¼‰
    if len(imgs) < 4:
        for kw in aliases + [poi.get("name","")]:
            if not kw: continue
            more = commons_images(kw, count=4 - len(imgs))
            for u in more:
                if u not in imgs:
                    imgs.append(u)
            if len(imgs) >= 4:
                break

    # 4) é«˜å¾·è¯¦æƒ…çš„ photos å†å…œåº•
    if len(imgs) < 4:
        for ph in (detail.get("photos") or []):
            url = ph.get("url")
            if url and url not in imgs:
                imgs.append(url)
            if len(imgs) >= 4:
                break

    # 5) æŠŠâ€œæœç´¢ç»“æœæ–‡æœ¬â€é‡Œçš„å¼€æ”¾æ—¶é—´è§£æè¿›æ¥
    openinfo = parse_open_hours_from_text(search_text)

    return render_cards_html(aliases[0], poi or {}, detail or {}, imgs, summary, openinfo)



# Travily æœç´¢å¼•æ“
tavily = TavilyMCPTool(
    max_results=5,
    description='è¿™æ˜¯ä¸€ä¸ªç±»ä¼¼è°·æ­Œå’Œç™¾åº¦çš„æœç´¢å¼•æ“ï¼Œæœç´¢çŸ¥è¯†ã€å¤©æ°”ã€è‚¡ç¥¨ã€ç”µå½±ã€å°è¯´ã€ç™¾ç§‘ç­‰éƒ½æ˜¯æ”¯æŒçš„å“¦ï¼Œå¦‚æœä½ ä¸ç¡®å®šå°±åº”è¯¥æœç´¢ä¸€ä¸‹ï¼Œè°¢è°¢ï¼ï¼ˆMCPç‰ˆï¼‰'
)

# å·¥å…·åˆ—è¡¨
tools = [tavily]

tool_names = 'or'.join([tool.name for tool in tools])
tool_descs = []
for t in tools:
    args_desc = []
    for name, info in t.args.items():
        args_desc.append({'name': name, 'description': info['description'] if 'description' in info else '', 'type': info['type']})
    args_desc = json.dumps(args_desc, ensure_ascii=False)
    tool_descs.append('%s: %s,args: %s' % (t.name, t.description, args_desc))
tool_descs = '\n'.join(tool_descs)

prompt_tpl = '''Today is {today}. Please Answer the following questions as best you can. You have access to the following tools:

{tool_descs}

These are chat history before:
{chat_history}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can be repeated zero or more times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

Question: {query}
{agent_scratchpad}
'''

def agent_execute(query, chat_history=[]):
    global tools, tool_names, tool_descs, prompt_tpl, llm, tokenizer
    
    agent_scratchpad = ''  # agentæ‰§è¡Œè¿‡ç¨‹
    while True:
        history = '\n'.join(['Question:%s\nAnswer:%s' % (his[0], his[1]) for his in chat_history])
        today = datetime.datetime.now().strftime('%Y-%m-%d')
        prompt = prompt_tpl.format(today=today, tool_descs=tool_descs, chat_history=history, tool_names=tool_names, query=query, agent_scratchpad=agent_scratchpad)
        print('\033[32m---ç­‰å¾…LLMè¿”å›... ...\n%s\n\033[0m' % prompt, flush=True)

        response = llm(prompt, user_stop_words=['Observation:'])
        print('\033[34m---LLMè¿”å›---\n%s\n---\033[34m' % response, flush=True)
        
        thought_i = response.rfind('Thought:')
        final_answer_i = response.rfind('\nFinal Answer:')
        action_i = response.rfind('\nAction:')
        action_input_i = response.rfind('\nAction Input:')
        observation_i = response.rfind('\nObservation:')
        
        if final_answer_i != -1 and thought_i < final_answer_i:
            final_answer = response[final_answer_i + len('\nFinal Answer:'):].strip()
            chat_history.append((query, final_answer))
            return True, final_answer, chat_history
        
        if not (thought_i < action_i < action_input_i):
            return False, 'LLMå›å¤æ ¼å¼å¼‚å¸¸', chat_history
        if observation_i == -1:
            observation_i = len(response)
            response = response + 'Observation: '
        thought = response[thought_i + len('Thought:'):action_i].strip()
        action = response[action_i + len('\nAction:'):action_input_i].strip()
        action_input = response[action_input_i + len('\nAction Input:'):observation_i].strip()
        
        the_tool = None
        for t in tools:
            if t.name == action:
                the_tool = t
                break
        if the_tool is None:
            observation = 'the tool not exist'
            agent_scratchpad = agent_scratchpad + response + observation + '\n'
            continue 
        
        try:
            action_input = json.loads(action_input)
            tool_ret = the_tool.invoke(input=json.dumps(action_input))
        except Exception as e:
            observation = 'the tool has error:{}'.format(e)
        else:
            observation = str(tool_ret)
        agent_scratchpad = agent_scratchpad + response + observation + '\n'

def agent_execute_with_retry(query, chat_history=[], retry_times=10):
    for i in range(retry_times):
        success, result, chat_history = agent_execute(query, chat_history=chat_history)
        if success:
            return success, result, chat_history
    return success, result, chat_history

def process_network(query):
    my_history = []
    success, result, my_history = agent_execute_with_retry(query, chat_history=my_history)
    return result

css = """
/* å…¨å±€æ ·å¼ */
body {
    font-family: 'Roboto', 'Microsoft YaHei', sans-serif !important;
    background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%) !important;
}

/* ä¸»å®¹å™¨ */
#main-header {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    border-radius: 15px;
    box-shadow: 0 10px 30px rgba(0,0,0,0.1);
    margin-bottom: 20px;
}

/* è¾“å…¥æ¡†æ ·å¼ */
.input-field {
    border: 2px solid #e0e0e0 !important;
    border-radius: 12px !important;
    padding: 12px !important;
    transition: all 0.3s ease !important;
    background: white !important;
}

.input-field:focus {
    border-color: #667eea !important;
    box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1) !important;
}

/* æŒ‰é’®æ ·å¼ */
.button-primary {
    background: linear-gradient(45deg, #667eea, #764ba2) !important;
    border: none !important;
    color: white !important;
    font-weight: 600 !important;
    padding: 12px 24px !important;
    border-radius: 25px !important;
    transition: all 0.3s ease !important;
    box-shadow: 0 4px 15px rgba(0,0,0,0.1) !important;
}

.button-primary:hover {
    transform: translateY(-2px) !important;
    box-shadow: 0 8px 25px rgba(0,0,0,0.2) !important;
}

/* èŠå¤©æ¡†æ ·å¼ */
.chatbot-container {
    border: 2px solid #e0e0e0 !important;
    border-radius: 15px !important;
    background: #fafafa !important;
    box-shadow: 0 5px 15px rgba(0,0,0,0.05) !important;
}

/* æ»‘å—æ ·å¼ */
.slider-container {
    background: #f8f9fa !important;
    border-radius: 12px !important;
    padding: 15px !important;
    box-shadow: 0 2px 10px rgba(0,0,0,0.05) !important;
}

/* å•é€‰æŒ‰é’®æ ·å¼ */
.radio-group {
    background: #f8f9fa !important;
    border-radius: 12px !important;
    padding: 15px !important;
    box-shadow: 0 2px 10px rgba(0,0,0,0.05) !important;
}

/* æ‰‹é£ç´æ ·å¼ */
.accordion-container {
    background: white !important;
    border-radius: 15px !important;
    box-shadow: 0 5px 15px rgba(0,0,0,0.08) !important;
    border: 1px solid #e0e0e0 !important;
}

/* è¡¨æ ¼æ ·å¼ */
table {
    width: 100% !important;
    border-collapse: collapse !important;
    margin: 20px 0 !important;
    background: white !important;
    border-radius: 10px !important;
    overflow: hidden !important;
    box-shadow: 0 5px 15px rgba(0,0,0,0.08) !important;
}


th {
    background: linear-gradient(135deg, #667eea, #764ba2) !important;
    color: white !important;
    padding: 15px !important;
    text-align: center !important;
    font-weight: 600 !important;
}

td {
    padding: 12px !important;
    text-align: center !important;
    border-bottom: 1px solid #e0e0e0 !important;
}

tr:nth-child(even) {
    background-color: #f8f9fa !important;
}

tr:hover {
    background-color: #e3f2fd !important;
    transition: background-color 0.3s ease !important;
}

/* ç¤ºä¾‹å®¹å™¨æ ·å¼ */
.example-container {
    background: #e3f2fd !important;
    border-radius: 10px !important;
    padding: 15px !important;
    margin: 15px 0 !important;
    border: 1px solid #bbdefb !important;
}

.example-item {
    background: white !important;
    border-radius: 8px !important;
    padding: 8px 12px !important;
    margin: 5px !important;
    display: inline-block !important;
    cursor: pointer !important;
    transition: all 0.2s ease !important;
    border: 1px solid #e0e0e0 !important;
}

.example-item:hover {
    background: #2196f3 !important;
    color: white !important;
    transform: translateY(-1px) !important;
    box-shadow: 0 3px 10px rgba(0,0,0,0.1) !important;
}

/* æ ‡ç­¾é¡µæ ·å¼ */
.tab-nav {
    background: white !important;
    border-radius: 15px 15px 0 0 !important;
    box-shadow: 0 5px 15px rgba(0,0,0,0.08) !important;
}

.tab-item {
    padding: 15px 25px !important;
    font-weight: 500 !important;
    transition: all 0.3s ease !important;
}

.tab-item:hover {
    background: #f0f4ff !important;
}

.tab-item.selected {
    background: linear-gradient(135deg, #667eea, #764ba2) !important;
    color: white !important;
}

/* åˆ—å¸ƒå±€æ ·å¼ */
.column {
    background: white !important;
    border-radius: 15px !important;
    padding: 20px !important;
    box-shadow: 0 5px 15px rgba(0,0,0,0.08) !important;
    border: 1px solid #e0e0e0 !important;
}
"""

# css="""
# #col-left {
#     margin: 0 auto;
#     max-width: 430px;
# }
# #col-mid {
#     margin: 0 auto;
#     max-width: 430px;
# }
# #col-right {
#     margin: 0 auto;
#     max-width: 430px;
# }
# #col-showcase {
#     margin: 0 auto;
#     max-width: 1100px;
# }
# #button {
#     color: blue;
# }

# """

# æ—…è¡Œè§„åˆ’å¸ˆåŠŸèƒ½

prompt = """ä½ ç°åœ¨æ˜¯ä¸€ä½ä¸“ä¸šçš„æ—…è¡Œè§„åˆ’å¸ˆï¼Œä½ çš„è´£ä»»æ˜¯æ ¹æ®æ—…è¡Œå‡ºå‘åœ°ã€ç›®çš„åœ°ã€å¤©æ•°ã€è¡Œç¨‹é£æ ¼ï¼ˆç´§å‡‘ã€é€‚ä¸­ã€ä¼‘é—²ï¼‰ã€é¢„ç®—ã€éšè¡Œäººæ•°ï¼Œå¸®åŠ©æˆ‘è§„åˆ’æ—…æ¸¸è¡Œç¨‹å¹¶ç”Ÿæˆè¯¦ç»†çš„æ—…è¡Œè®¡åˆ’è¡¨ã€‚è¯·ä½ ä»¥è¡¨æ ¼çš„æ–¹å¼å‘ˆç°ç»“æœã€‚æ—…è¡Œè®¡åˆ’è¡¨çš„è¡¨å¤´è¯·åŒ…å«æ—¥æœŸã€åœ°ç‚¹ã€è¡Œç¨‹è®¡åˆ’ã€äº¤é€šæ–¹å¼ã€é¤é¥®å®‰æ’ã€ä½å®¿å®‰æ’ã€è´¹ç”¨ä¼°ç®—ã€å¤‡æ³¨ã€‚æ‰€æœ‰è¡¨å¤´éƒ½ä¸ºå¿…å¡«é¡¹ï¼Œè¯·åŠ æ·±æ€è€ƒè¿‡ç¨‹ï¼Œä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š

1. æ—¥æœŸè¯·ä»¥DayNä¸ºæ ¼å¼å¦‚Day1ï¼Œæ˜ç¡®æ ‡è¯†æ¯å¤©çš„è¡Œç¨‹ã€‚
2. åœ°ç‚¹éœ€è¦å‘ˆç°å½“å¤©æ‰€åœ¨åŸå¸‚ï¼Œè¯·æ ¹æ®æ—¥æœŸã€è€ƒè™‘åœ°ç‚¹çš„åœ°ç†ä½ç½®è¿œè¿‘ï¼Œä¸¥æ ¼ä¸”åˆç†åˆ¶å®šåœ°ç‚¹ï¼Œç¡®ä¿è¡Œç¨‹é¡ºç•…ã€‚
3. è¡Œç¨‹è®¡åˆ’éœ€åŒ…å«ä½ç½®ã€æ—¶é—´ã€æ´»åŠ¨ï¼Œå…¶ä¸­ä½ç½®éœ€è¦æ ¹æ®åœ°ç†ä½ç½®çš„è¿œè¿‘è¿›è¡Œæ’åºã€‚ä½ç½®çš„æ•°é‡å¯ä»¥æ ¹æ®è¡Œç¨‹é£æ ¼çµæ´»è°ƒæ•´ï¼Œå¦‚ä¼‘é—²åˆ™ä½ç½®æ•°é‡è¾ƒå°‘ã€ç´§å‡‘åˆ™ä½ç½®æ•°é‡è¾ƒå¤šã€‚æ—¶é—´éœ€è¦æŒ‰ç…§ä¸Šåˆã€ä¸­åˆã€æ™šä¸Šåˆ¶å®šï¼Œå¹¶ç»™å‡ºæ¯ä¸€ä¸ªä½ç½®æ‰€åœç•™çš„æ—¶é—´ï¼ˆå¦‚ä¸Šåˆ10ç‚¹-ä¸­åˆ12ç‚¹ï¼‰ã€‚æ´»åŠ¨éœ€è¦å‡†ç¡®æè¿°åœ¨ä½ç½®å‘ç”Ÿçš„å¯¹åº”æ´»åŠ¨ï¼ˆå¦‚å‚è§‚åšç‰©é¦†ã€æ¸¸è§ˆå…¬å›­ã€åƒé¥­ç­‰ï¼‰ï¼Œå¹¶éœ€æ ¹æ®ä½ç½®åœç•™æ—¶é—´åˆç†å®‰æ’æ´»åŠ¨ç±»å‹ã€‚
4. äº¤é€šæ–¹å¼éœ€æ ¹æ®åœ°ç‚¹ã€è¡Œç¨‹è®¡åˆ’ä¸­çš„æ¯ä¸ªä½ç½®çš„åœ°ç†è·ç¦»åˆç†é€‰æ‹©ï¼Œå¦‚æ­¥è¡Œã€åœ°é“ã€å‡ºç§Ÿè½¦ã€ç«è½¦ã€é£æœºç­‰ä¸åŒçš„äº¤é€šæ–¹å¼ï¼Œå¹¶å°½å¯èƒ½è¯¦ç»†è¯´æ˜ã€‚
5. é¤é¥®å®‰æ’éœ€åŒ…å«æ¯é¤çš„æ¨èé¤å…ã€ç±»å‹ï¼ˆå¦‚æœ¬åœ°ç‰¹è‰²ã€å¿«é¤ç­‰ï¼‰ã€é¢„ç®—èŒƒå›´ï¼Œå°±è¿‘é€‰æ‹©ã€‚
6. ä½å®¿å®‰æ’éœ€åŒ…å«æ¯æ™šçš„æ¨èé…’åº—æˆ–ä½å®¿ç±»å‹ï¼ˆå¦‚é…’åº—ã€æ°‘å®¿ç­‰ï¼‰ã€åœ°å€ã€é¢„ä¼°è´¹ç”¨ï¼Œå°±è¿‘é€‰æ‹©ã€‚
7. è´¹ç”¨ä¼°ç®—éœ€åŒ…å«æ¯å¤©çš„é¢„ä¼°æ€»è´¹ç”¨ï¼Œå¹¶æ³¨æ˜å„é¡¹è´¹ç”¨çš„ç»†åˆ†ï¼ˆå¦‚äº¤é€šè´¹ã€é¤é¥®è´¹ã€é—¨ç¥¨è´¹ç­‰ï¼‰ã€‚
8. å¤‡æ³¨ä¸­éœ€è¦åŒ…æ‹¬å¯¹åº”è¡Œç¨‹è®¡åˆ’éœ€è¦è€ƒè™‘åˆ°çš„æ³¨æ„äº‹é¡¹ï¼Œä¿æŒå¤šæ ·æ€§ï¼Œæ¶‰åŠé¥®é£Ÿã€æ–‡åŒ–ã€å¤©æ°”ã€è¯­è¨€ç­‰æ–¹é¢çš„æé†’ã€‚
9. è¯·ç‰¹åˆ«è€ƒè™‘éšè¡Œäººæ•°çš„ä¿¡æ¯ï¼Œç¡®ä¿è¡Œç¨‹å’Œä½å®¿å®‰æ’èƒ½æ»¡è¶³æ‰€æœ‰éšè¡Œäººå‘˜çš„éœ€æ±‚ã€‚
10.æ—…æ¸¸æ€»ä½“è´¹ç”¨ä¸èƒ½è¶…è¿‡é¢„ç®—ã€‚

ç°åœ¨è¯·ä½ ä¸¥æ ¼éµå®ˆä»¥ä¸Šè§„åˆ™ï¼Œæ ¹æ®æˆ‘çš„æ—…è¡Œå‡ºå‘åœ°ã€ç›®çš„åœ°ã€å¤©æ•°ã€è¡Œç¨‹é£æ ¼ï¼ˆç´§å‡‘ã€é€‚ä¸­ã€ä¼‘é—²ï¼‰ã€é¢„ç®—ã€éšè¡Œäººæ•°ï¼Œç”Ÿæˆåˆç†ä¸”è¯¦ç»†çš„æ—…è¡Œè®¡åˆ’è¡¨ã€‚è®°ä½ä½ è¦æ ¹æ®æˆ‘æä¾›çš„æ—…è¡Œç›®çš„åœ°ã€å¤©æ•°ç­‰ä¿¡æ¯ä»¥è¡¨æ ¼å½¢å¼ç”Ÿæˆæ—…è¡Œè®¡åˆ’è¡¨ï¼Œæœ€ç»ˆç­”æ¡ˆä¸€å®šæ˜¯è¡¨æ ¼å½¢å¼ã€‚ä»¥ä¸‹æ˜¯æ—…è¡Œçš„åŸºæœ¬ä¿¡æ¯ï¼š
æ—…æ¸¸å‡ºå‘åœ°ï¼š{}ï¼Œæ—…æ¸¸ç›®çš„åœ°ï¼š{} ï¼Œå¤©æ•°ï¼š{}å¤© ï¼Œè¡Œç¨‹é£æ ¼ï¼š{} ï¼Œé¢„ç®—ï¼š{}ï¼Œéšè¡Œäººæ•°ï¼š{}, ç‰¹æ®Šåå¥½ã€è¦æ±‚ï¼š{}

"""

sys_prompt = """
ä½ ç°åœ¨æ˜¯ä¸€ä½ä¸“ä¸šçš„æ—…è¡Œè§„åˆ’å¸ˆï¼Œä½ çš„è´£ä»»æ˜¯æ ¹æ®æ—…è¡Œå‡ºå‘åœ°ã€ç›®çš„åœ°ã€å¤©æ•°ã€è¡Œç¨‹é£æ ¼ï¼ˆç´§å‡‘ã€é€‚ä¸­ã€ä¼‘é—²ï¼‰ã€é¢„ç®—ã€éšè¡Œäººæ•°ï¼Œå¸®åŠ©æˆ‘è§„åˆ’æ—…æ¸¸è¡Œç¨‹å¹¶ç”Ÿæˆè¯¦ç»†çš„æ—…è¡Œè®¡åˆ’è¡¨ã€‚è¯·ä½ ä»¥è¡¨æ ¼çš„æ–¹å¼å‘ˆç°ç»“æœã€‚æ—…è¡Œè®¡åˆ’è¡¨çš„è¡¨å¤´è¯·åŒ…å«æ—¥æœŸã€åœ°ç‚¹ã€è¡Œç¨‹è®¡åˆ’ã€äº¤é€šæ–¹å¼ã€é¤é¥®å®‰æ’ã€ä½å®¿å®‰æ’ã€è´¹ç”¨ä¼°ç®—ã€å¤‡æ³¨ã€‚æ‰€æœ‰è¡¨å¤´éƒ½ä¸ºå¿…å¡«é¡¹ï¼Œè¯·åŠ æ·±æ€è€ƒè¿‡ç¨‹ï¼Œä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š

1. æ—¥æœŸè¯·ä»¥DayN|yyyy-mm-ddä¸ºæ ¼å¼å¦‚Day1 1990-01-01ï¼Œæ˜ç¡®æ ‡è¯†æ¯å¤©çš„è¡Œç¨‹,å¦‚æœæœ‰å‡ºå‘æ—¶é—´ï¼Œåˆ™å–å‡ºå‘æ—¶é—´ï¼Œå¦åˆ™æ—¥æœŸéœ€è¦å–å½“å‰æŸ¥è¯¢çš„æœ€æ–°æ—¥æœŸã€‚
2. åœ°ç‚¹éœ€è¦å‘ˆç°å½“å¤©æ‰€åœ¨åŸå¸‚ï¼Œè¯·æ ¹æ®æ—¥æœŸã€è€ƒè™‘åœ°ç‚¹çš„åœ°ç†ä½ç½®è¿œè¿‘ï¼Œä¸¥æ ¼ä¸”åˆç†åˆ¶å®šåœ°ç‚¹ï¼Œç¡®ä¿è¡Œç¨‹é¡ºç•…ã€‚
3. è¡Œç¨‹è®¡åˆ’éœ€åŒ…å«ä½ç½®ã€æ—¶é—´ã€æ´»åŠ¨ï¼Œå…¶ä¸­ä½ç½®éœ€è¦æ ¹æ®åœ°ç†ä½ç½®çš„è¿œè¿‘è¿›è¡Œæ’åºã€‚ä½ç½®çš„æ•°é‡å¯ä»¥æ ¹æ®è¡Œç¨‹é£æ ¼çµæ´»è°ƒæ•´ï¼Œå¦‚ä¼‘é—²åˆ™ä½ç½®æ•°é‡è¾ƒå°‘ã€ç´§å‡‘åˆ™ä½ç½®æ•°é‡è¾ƒå¤šã€‚æ—¶é—´éœ€è¦æŒ‰ç…§ä¸Šåˆã€ä¸­åˆã€æ™šä¸Šåˆ¶å®šï¼Œå¹¶ç»™å‡ºæ¯ä¸€ä¸ªä½ç½®æ‰€åœç•™çš„æ—¶é—´ï¼ˆå¦‚ä¸Šåˆ10ç‚¹-ä¸­åˆ12ç‚¹ï¼‰ã€‚æ´»åŠ¨éœ€è¦å‡†ç¡®æè¿°åœ¨ä½ç½®å‘ç”Ÿçš„å¯¹åº”æ´»åŠ¨ï¼ˆå¦‚å‚è§‚åšç‰©é¦†ã€æ¸¸è§ˆå…¬å›­ã€åƒé¥­ç­‰ï¼‰ï¼Œå¹¶éœ€æ ¹æ®ä½ç½®åœç•™æ—¶é—´åˆç†å®‰æ’æ´»åŠ¨ç±»å‹ã€‚
4. äº¤é€šæ–¹å¼éœ€æ ¹æ®åœ°ç‚¹ã€è¡Œç¨‹è®¡åˆ’ä¸­çš„æ¯ä¸ªä½ç½®çš„åœ°ç†è·ç¦»åˆç†é€‰æ‹©ï¼Œå¦‚æ­¥è¡Œã€åœ°é“ã€å‡ºç§Ÿè½¦ã€ç«è½¦ã€é£æœºç­‰ä¸åŒçš„äº¤é€šæ–¹å¼ï¼Œå¹¶å°½å¯èƒ½è¯¦ç»†è¯´æ˜ã€‚
5. é¤é¥®å®‰æ’éœ€åŒ…å«æ¯é¤çš„æ¨èé¤å…ã€ç±»å‹ï¼ˆå¦‚æœ¬åœ°ç‰¹è‰²ã€å¿«é¤ç­‰ï¼‰ã€é¢„ç®—èŒƒå›´ï¼Œå°±è¿‘é€‰æ‹©ã€‚
6. ä½å®¿å®‰æ’éœ€åŒ…å«æ¯æ™šçš„æ¨èé…’åº—æˆ–ä½å®¿ç±»å‹ï¼ˆå¦‚é…’åº—ã€æ°‘å®¿ç­‰ï¼‰ã€åœ°å€ã€é¢„ä¼°è´¹ç”¨ï¼Œå°±è¿‘é€‰æ‹©ã€‚
7. è´¹ç”¨ä¼°ç®—éœ€åŒ…å«æ¯å¤©çš„é¢„ä¼°æ€»è´¹ç”¨ï¼Œå¹¶æ³¨æ˜å„é¡¹è´¹ç”¨çš„ç»†åˆ†ï¼ˆå¦‚äº¤é€šè´¹ã€é¤é¥®è´¹ã€é—¨ç¥¨è´¹ç­‰ï¼‰ã€‚
8. å¤‡æ³¨ä¸­éœ€è¦åŒ…æ‹¬å¯¹åº”è¡Œç¨‹è®¡åˆ’éœ€è¦è€ƒè™‘åˆ°çš„æ³¨æ„äº‹é¡¹ï¼Œä¿æŒå¤šæ ·æ€§ï¼Œæ¶‰åŠé¥®é£Ÿã€æ–‡åŒ–ã€è¯­è¨€ç­‰æ–¹é¢çš„æé†’ã€‚
9. åˆ—å‡ºæ¯å¤©çš„å¤©æ°”æƒ…å†µï¼Œç»“åˆé«˜å¾·åœ°å›¾å·¥å…·ï¼Œè·å–å¯¹åº”çš„å¤©æ°”ï¼Œç»“åˆæ¯å¤©çš„å¤©æ°”æç¤º
10. è¯·ç‰¹åˆ«è€ƒè™‘éšè¡Œäººæ•°çš„ä¿¡æ¯ï¼Œç¡®ä¿è¡Œç¨‹å’Œä½å®¿å®‰æ’èƒ½æ»¡è¶³æ‰€æœ‰éšè¡Œäººå‘˜çš„éœ€æ±‚ã€‚
11.æ—…æ¸¸æ€»ä½“è´¹ç”¨ä¸èƒ½è¶…è¿‡é¢„ç®—ã€‚


ç°åœ¨è¯·ä½ ä¸¥æ ¼éµå®ˆä»¥ä¸Šè§„åˆ™ï¼Œæ ¹æ®æˆ‘çš„æ—…è¡Œå‡ºå‘åœ°ã€ç›®çš„åœ°ã€å¤©æ•°ã€è¡Œç¨‹é£æ ¼ï¼ˆç´§å‡‘ã€é€‚ä¸­ã€ä¼‘é—²ï¼‰ã€é¢„ç®—ã€éšè¡Œäººæ•°ï¼Œç”Ÿæˆåˆç†ä¸”è¯¦ç»†çš„æ—…è¡Œè®¡åˆ’è¡¨ã€‚è®°ä½ä½ è¦æ ¹æ®æˆ‘æä¾›çš„æ—…è¡Œç›®çš„åœ°ã€å¤©æ•°ç­‰ä¿¡æ¯ä»¥è¡¨æ ¼å½¢å¼ç”Ÿæˆæ—…è¡Œè®¡åˆ’è¡¨ï¼Œæœ€ç»ˆç­”æ¡ˆä¸€å®šæ˜¯è¡¨æ ¼å½¢å¼ã€‚ä»¥ä¸‹æ˜¯æ—…è¡Œçš„åŸºæœ¬ä¿¡æ¯ï¼š
æ—…æ¸¸å‡ºå‘åœ°ï¼š{}ï¼Œæ—…æ¸¸ç›®çš„åœ°ï¼š{} ï¼Œå¤©æ•°ï¼š{}å¤© ï¼Œè¡Œç¨‹é£æ ¼ï¼š{} ï¼Œé¢„ç®—ï¼š{}ï¼Œéšè¡Œäººæ•°ï¼š{}ï¼Œå‡ºå‘æ—¶é—´ï¼š{}, ç‰¹æ®Šåå¥½ã€è¦æ±‚ï¼š{}

"""
# def chat(chat_destination, chat_history, chat_departure, chat_days, chat_style, chat_budget, chat_people, chat_other):
    
#     ROUTE_JSON_SUFFIX = """
#     åœ¨è¡¨æ ¼ä¹‹åï¼Œå¦èµ·ä¸€è¡Œï¼Œä»…è¾“å‡ºä¸€æ®µ JSONï¼ˆä¸è¦è§£é‡Šï¼‰ï¼š
#     {
#     "route": [
#         {"day":"Day1","city":"<å½“å¤©åŸå¸‚>","stops":["<ç¬¬1ç«™>","<ç¬¬2ç«™>","..."]},
#         {"day":"Day2","city":"<å½“å¤©åŸå¸‚>","stops":["..."]}
#     ]
#     }
#     æ³¨æ„ï¼šstops ç”¨â€œå¯è¢«åœ°å›¾è¯†åˆ«çš„åœ°å/POIâ€ï¼Œå¦‚â€œå¤–æ»©â€â€œä¸Šæµ·ç«™â€â€œå—äº¬è·¯æ­¥è¡Œè¡—â€ç­‰ã€‚
#     """

#     final_query = prompt.format(
#         chat_departure, chat_destination, chat_days, chat_style, chat_budget, chat_people, chat_other
#     ) + ROUTE_JSON_SUFFIX
#     chat_history.append((chat_destination, ""))

#     response = qwen_client.chat.completions.create(
#         model="qwen-plus",
#         messages=[{"role": "user", "content": final_query}],
#         stream=True,
#         temperature=0.7
#     )

#     answer = ""
#     information = 'æ—…æ¸¸å‡ºå‘åœ°ï¼š{}ï¼Œæ—…æ¸¸ç›®çš„åœ°ï¼š{} ï¼Œå¤©æ•°ï¼š{} ï¼Œè¡Œç¨‹é£æ ¼ï¼š{} ï¼Œé¢„ç®—ï¼š{}ï¼Œéšè¡Œäººæ•°ï¼š{}'.format(
#         chat_departure, chat_destination, chat_days, chat_style, chat_budget, chat_people
#     )

#     # â€”â€” æµå¼æŠŠæ–‡æœ¬æ¨ç»™èŠå¤©çª—å£
#     for chunk in response:
#         if chunk.choices[0].delta.content:
#             answer += chunk.choices[0].delta.content
#             chat_history[-1] = (information, answer)
#             # æš‚æ—¶ä¸ç»™åœ°å›¾ï¼ˆç¬¬ä¸‰ä¸ªè¾“å‡ºç•™ç©ºï¼‰
#             yield "", chat_history, ""

#     # â€”â€” æµå¼ç»“æŸåï¼šå°è¯•è§£æè·¯çº¿ JSON â†’ åœ°ç†ç¼–ç  â†’ ç”Ÿæˆé™æ€åœ°å›¾
#     map_html = "<div style='color:#888'>æœªè¯†åˆ«åˆ°è¡Œç¨‹ JSONï¼ˆ\"route\"ï¼‰ï¼Œæš‚æ— æ³•ç»˜åˆ¶åœ°å›¾ã€‚</div>"
#     route_list = extract_route_json(answer)
#     map_html = "<div style='color:#888'>æœªè¯†åˆ«åˆ°è¡Œç¨‹ JSONï¼ˆ\"route\"ï¼‰ã€‚</div>"
#     if route_list:
#         day_points = geocode_stops_by_day(route_list, chat_destination or "")
#         map_html = build_multiday_amap_html_interactive(day_points)

#     yield "", chat_history, map_html

async def chat(chat_destination, chat_history, chat_departure, chat_days, chat_style, chat_budget, chat_people, chat_other,chat_start_date):
    # stream_model = ChatModel(config, stream=True)
    ROUTE_JSON_SUFFIX = """
    åœ¨è¡¨æ ¼ä¹‹åï¼Œå¦èµ·ä¸€è¡Œï¼Œä»…è¾“å‡ºä¸€æ®µ JSONï¼ˆä¸è¦è§£é‡Šï¼‰ï¼š
    {
    "route": [
        {"day":"Day1","city":"<å½“å¤©åŸå¸‚>","stops":["<ç¬¬1ç«™>","<ç¬¬2ç«™>","..."]},
        {"day":"Day2","city":"<å½“å¤©åŸå¸‚>","stops":["..."]}
    ]
    }
    æ³¨æ„ï¼šstops ç”¨â€œå¯è¢«åœ°å›¾è¯†åˆ«çš„åœ°å/POIâ€ï¼Œå¦‚â€œå¤–æ»©â€â€œä¸Šæµ·ç«™â€â€œå—äº¬è·¯æ­¥è¡Œè¡—â€ç­‰ã€‚
    """
    chat_start_date = datetime.fromtimestamp(chat_start_date).strftime('%Y-%m-%d %H:%M:%S')

    final_query = sys_prompt.format(chat_departure, chat_destination, chat_days, chat_style, chat_budget,  chat_people, chat_other,chat_start_date) + ROUTE_JSON_SUFFIX

    # å°†é—®é¢˜è®¾ä¸ºå†å²å¯¹è¯
    chat_history.append((chat_destination, ''))

    # æµå¼è¿”å›å¤„ç†
    answer = ""
    information = 'æ—…æ¸¸å‡ºå‘åœ°ï¼š{}ï¼Œæ—…æ¸¸ç›®çš„åœ°ï¼š{} ï¼Œå¤©æ•°ï¼š{} ï¼Œè¡Œç¨‹é£æ ¼ï¼š{} ï¼Œé¢„ç®—ï¼š{}ï¼Œéšè¡Œäººæ•°ï¼š{}ï¼Œå‡ºå‘æ—¶é—´ï¼š{}'.format(
        chat_departure, chat_destination, chat_days, chat_style, chat_budget, chat_people, chat_start_date)

    checkpointer = InMemorySaver()
    from langchain_core.messages import  HumanMessage
    
    try:
#        tools = asyncio.run(client.get_tools())
        tools = await client.get_tools()
        agent = create_react_agent(llmMCP, tools, prompt=final_query, checkpointer=checkpointer)
        logger.info(f"Weather_server: è·å–åˆ°çš„å·¥å…·åˆ—è¡¨: {[[tool.name, tool.description] for tool in tools]}")
        config = {
            "configurable": {
                "thread_id": "1"  
            },
            "recursion_limit": 100  # âœ… å¢åŠ åˆ° 100 æ­¥ï¼ˆæ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
        }

 
 # ä½¿ç”¨ astream_events æ¥è·å–æ‰€æœ‰äº‹ä»¶
        
        async for event in agent.astream_events({"messages": [HumanMessage(content=final_query)]}, config=config, version="v2"):
            # print("event:", event)
            if event["event"] == "on_chat_model_stream":
                # print("event:", event  )
                content = event["data"].get("chunk", {}).content
                if content:
                    answer += content
                    chat_history[-1] = (information, answer)
                    yield "", chat_history, ""
           #print(content, end="", flush=True)
        
        # â€”â€” æµå¼æŠŠæ–‡æœ¬æ¨ç»™èŠå¤©çª—å£
        # for chunk in response:
        #     if chunk.choices[0].delta.content:
        #         answer += chunk.choices[0].delta.content
        #         chat_history[-1] = (information, answer)
        #         # æš‚æ—¶ä¸ç»™åœ°å›¾ï¼ˆç¬¬ä¸‰ä¸ªè¾“å‡ºç•™ç©ºï¼‰
        #         yield "", chat_history, ""
        
    except Exception as e:
        logger.error(f"Weather_server: è°ƒç”¨å¤©æ°”æœåŠ¡æ—¶å‡ºé”™: {str(e)}")
        response = f"æŠ±æ­‰ï¼Œå¤©æ°”æœåŠ¡è°ƒç”¨å¤±è´¥: {str(e)}"
    
    # â€”â€” æµå¼ç»“æŸåï¼šå°è¯•è§£æè·¯çº¿ JSON â†’ åœ°ç†ç¼–ç  â†’ ç”Ÿæˆé™æ€åœ°å›¾
    route_list = extract_route_json(answer)
    map_html = "<div style='color:#888'>æœªè¯†åˆ«åˆ°è¡Œç¨‹ JSONï¼ˆ\"route\"ï¼‰ã€‚</div>"
    if route_list:
        day_points = geocode_stops_by_day(route_list, chat_destination or "")
        map_html = build_multiday_amap_html_interactive(day_points)

    yield "", chat_history, map_html

# Gradioæ¥å£å®šä¹‰
"""
    <!DOCTYPE html>
        <html lang="zh-CN">        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <style>
                body {
                    font-family: 'Arial', sans-serif;
                    background-color: #f8f9fa;
                    margin: 0;
                    padding: 10px;
                }
                .container {
                    max-width: 1500px;
                    margin: auto;
                    background-color: #ffffff;
                    border-radius: 10px;
                    box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
                    padding: 10px;
                }
                .logo img {
                    display: block;
                    margin: 0 auto;
                    border-radius: 7px;
                }
                .content h2 {
                    text-align: center;
                    color: #999999;
                    font-size: 24px;
                    margin-top: 20px;
                }
                .content p {
                    text-align: center;
                    color: #cccccc;
                    font-size: 16px;
                    line-height: 1.5;
                    margin-top: 30px;
                }
            </style>
        </head>
    <body>
            <div class="container">
                <div class="content">
                    <h2>ğŸ˜€ æ¬¢è¿æ¥åˆ°â€œNVIDIA-TRAVELERâ€ï¼Œæ‚¨çš„ä¸“å±æ—…è¡Œä¼™ä¼´ï¼æˆ‘ä»¬è‡´åŠ›äºä¸ºæ‚¨æä¾›ä¸ªæ€§åŒ–çš„æ—…è¡Œè§„åˆ’ã€é™ªä¼´å’Œåˆ†äº«æœåŠ¡ï¼Œè®©æ‚¨çš„æ—…ç¨‹å……æ»¡ä¹è¶£å¹¶ç•™ä¸‹éš¾å¿˜å›å¿†ã€‚\n</h2>     
                </div>
            </div>
    </body>
"""

with gr.Blocks(css=css) as demo:
    html_code = """
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            margin: 0;
            padding: 20px;
            min-height: 100vh;
        }
        .main-container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            overflow: hidden;
        }
        .header-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 40px 20px;
            text-align: center;
            color: white;
        }
        .logo-container {
            margin-bottom: 20px;
        }
        .logo-img {
            max-width: 200px;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
            transition: transform 0.3s ease;
        }
        .logo-img:hover {
            transform: scale(1.05);
        }
        .title-main {
            font-size: 2.2em;
            font-weight: 700;
            margin: 20px 0 10px 0;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        .subtitle {
            font-size: 1.2em;
            font-weight: 300;
            opacity: 0.9;
            max-width: 800px;
            margin: 0 auto;
            line-height: 1.6;
            word-wrap: break-word; /* å…³é”®ï¼šå…è®¸é•¿å•è¯æ¢è¡Œ */
            white-space: pre-line; /* ä¿ç•™æ¢è¡Œç¬¦ */
            text-align: center; /* å±…ä¸­å¯¹é½ */
        }
        .features-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            padding: 30px;
            background: #f8f9fa;
        }
        .feature-card {
            background: white;
            border-radius: 15px;
            padding: 25px;
            text-align: center;
            box-shadow: 0 5px 15px rgba(0,0,0,0.05);
            transition: all 0.3s ease;
        }
        .feature-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 30px rgba(0,0,0,0.1);
        }
        .feature-icon {
            font-size: 2.5em;
            margin-bottom: 15px;
            color: #667eea;
        }
        .feature-title {
            font-weight: 600;
            margin-bottom: 10px;
            color: #333;
        }
        .feature-desc {
            color: #666;
            font-size: 0.9em;
            line-height: 1.5;
            word-wrap: break-word;
            white-space: normal;
        }
        
        /* å“åº”å¼è®¾è®¡ */
        @media (max-width: 768px) {
            .header-section {
                padding: 30px 15px;
            }
            .title-main {
                font-size: 1.8em;
            }
            .subtitle {
                font-size: 1em;
                padding: 0 15px;
            }
            .features-grid {
                grid-template-columns: 1fr;
                padding: 20px;
                gap: 15px;
            }
            .feature-card {
                padding: 20px;
            }
            .feature-icon {
                font-size: 2em;
            }
            .logo-img {
                max-width: 150px;
            }
        }
        
        @media (max-width: 480px) {
            .title-main {
                font-size: 1.5em;
            }
            .subtitle {
                font-size: 0.9em;
            }
            .feature-card {
                padding: 15px;
            }
        }
    </style>
</head>
<body>
    <div class="main-container">
        <div class="header-section">
            <div class="logo-container">
                <img id="logo-img" src="https://img.picui.cn/free/2024/09/25/66f3cdc149a78.png" alt="NVIDIA-TRAVEL Logo" class="logo-img">
            </div>
            <h1 class="title-main">ğŸ˜€ æ¬¢è¿æ¥åˆ°"NVIDIA-TRAVEL"</h1>
            <p class="subtitle">æ‚¨çš„ä¸“å±æ—…è¡Œä¼™ä¼´ï¼æˆ‘ä»¬è‡´åŠ›äºä¸ºæ‚¨æä¾›ä¸ªæ€§åŒ–çš„æ—…è¡Œè§„åˆ’ã€é™ªä¼´å’Œåˆ†äº«æœåŠ¡ï¼Œè®©æ‚¨çš„æ—…ç¨‹å……æ»¡ä¹è¶£å¹¶ç•™ä¸‹éš¾å¿˜å›å¿†ã€‚</p>
        </div>
        
        <div class="features-grid">
            <div class="feature-card">
                <div class="feature-icon">ğŸ—ºï¸</div>
                <h3 class="feature-title">æ™ºèƒ½æ—…è¡Œè§„åˆ’</h3>
                <p class="feature-desc">æ ¹æ®æ‚¨çš„éœ€æ±‚ç”Ÿæˆè¯¦ç»†çš„æ—…è¡Œè®¡åˆ’è¡¨ï¼ŒåŒ…å«è¡Œç¨‹ã€äº¤é€šã€ä½å®¿ç­‰å…¨æ–¹ä½å®‰æ’</p>
            </div>
            <div class="feature-card">
                <div class="feature-icon">ğŸ¤–</div>
                <h3 class="feature-title">AIæ™ºèƒ½é—®ç­”</h3>
                <p class="feature-desc">åŸºäºçŸ¥è¯†åº“å’Œç½‘ç»œæœç´¢ï¼Œä¸ºæ‚¨æä¾›å‡†ç¡®çš„æ—…æ¸¸ä¿¡æ¯å’Œå®ç”¨å»ºè®®</p>
            </div>
            <div class="feature-card">
                <div class="feature-icon">ğŸŒ¤ï¸</div>
                <h3 class="feature-title">å®æ—¶å¤©æ°”æŸ¥è¯¢&é…’åº—é¤é¥®æœç´¢</h3>
                <p class="feature-desc">æä¾›ç›®çš„åœ°å¤©æ°”é¢„æŠ¥å’Œé™„è¿‘é…’åº—é¤é¥®ï¼ŒåŠ©æ‚¨åˆç†å®‰æ’è¡Œç¨‹</p>
            </div>
        </div>
    </div>
</body>
</html>
"""
    gr.HTML(html_code)
    with gr.Tab("æ—…è¡Œè§„åˆ’åŠ©æ‰‹"):
        # with gr.Group():
        with gr.Row():
            chat_departure = gr.Textbox(label="è¾“å…¥æ—…æ¸¸å‡ºå‘åœ°", placeholder="è¯·ä½ è¾“å…¥å‡ºå‘åœ°")
            gr.Examples(["åˆè‚¥", "éƒ‘å·", "è¥¿å®‰", "åŒ—äº¬", "å¹¿å·", "å¤§è¿","å¦é—¨","å—äº¬", "å¤§ç†", "ä¸Šæµ·","æˆéƒ½","é»„å±±"], chat_departure, label='å‡ºå‘åœ°ç¤ºä¾‹',examples_per_page= 12)
            chat_destination = gr.Textbox(label="è¾“å…¥æ—…æ¸¸ç›®çš„åœ°", placeholder="è¯·ä½ è¾“å…¥æƒ³å»çš„åœ°æ–¹")
            gr.Examples(["åˆè‚¥", "éƒ‘å·", "è¥¿å®‰", "åŒ—äº¬", "å¹¿å·", "å¤§è¿","å¦é—¨","å—äº¬", "å¤§ç†", "ä¸Šæµ·","æˆéƒ½","é»„å±±"], chat_destination, label='ç›®çš„åœ°ç¤ºä¾‹',examples_per_page= 12)
        
        with gr.Accordion("ä¸ªæ€§åŒ–é€‰æ‹©ï¼ˆå¤©æ•°ï¼Œè¡Œç¨‹é£æ ¼ï¼Œé¢„ç®—ï¼Œéšè¡Œäººæ•°ï¼‰", open=True):
            with gr.Group():
                with gr.Row():  # æ–°å¢ä¸€è¡Œç”¨äºæ—¥æœŸé€‰æ‹©
                    chat_start_date = gr.DateTime(label="å‡ºå‘æ—¶é—´",interactive=True,elem_id="datetime-input")  # æ˜¾å¼è®¾ç½®ä¸ºTrueï¼ˆå¯é€‰ï¼‰   # æ—¥æœŸ+æ—¶é—´é€‰æ‹©(label="é€‰æ‹©å‡ºå‘æ—¥æœŸ", value=None)  # é»˜è®¤ä¸ºç©ºï¼Œç”¨æˆ·å¿…é¡»é€‰æ‹©
                with gr.Row():
                    chat_days = gr.Slider(minimum=1, maximum=10, step=1, value=3, label='æ—…æ¸¸å¤©æ•°')
                    chat_style = gr.Radio(choices=['ç´§å‡‘', 'é€‚ä¸­', 'ä¼‘é—²'], value='é€‚ä¸­', label='è¡Œç¨‹é£æ ¼',elem_id="button")
                    chat_budget = gr.Textbox(label="è¾“å…¥é¢„ç®—(å¸¦ä¸Šå•ä½)", placeholder="è¯·ä½ è¾“å…¥é¢„ç®—")
                with gr.Row():   
                    chat_people = gr.Textbox(label="è¾“å…¥éšè¡Œäººæ•°", placeholder="è¯·ä½ è¾“å…¥éšè¡Œäººæ•°")
                    chat_other = gr.Textbox(label="ç‰¹æ®Šåå¥½ã€è¦æ±‚(å¯å†™æ— )", placeholder="è¯·ä½ ç‰¹æ®Šåå¥½ã€è¦æ±‚")
                # èŠå¤©å¯¹è¯æ¡†
        llm_submit_tab = gr.Button("å‘é€", visible=True,elem_id="button")
        chatbot = gr.Chatbot([], elem_id="chat-box", label="èŠå¤©çª—å£", height=600)
        planner_output_md = gr.Markdown(label="è§„åˆ’ç»“æœ")

        # æ·»åŠ åœ°å›¾æ˜¾ç¤ºåŒºåŸŸ
        route_map_html = gr.HTML(label="åœ°å›¾", elem_id="route-maps")
        
        # æŒ‰é’®å‡ºå‘é€»è¾‘
        llm_submit_tab.click(fn=chat, inputs=[chat_destination, chatbot, chat_departure, chat_days, chat_style, chat_budget, chat_people, chat_other,chat_start_date], outputs=[ chat_destination,chatbot, route_map_html])

    def respond(message, chat_history, use_kb):
            return process_question(chat_history, use_kb, message)
    def clear_chat(chat_history):
        return clear_history(chat_history)    
    # with gr.Tab("æ—…æ¸¸é—®ç­”åŠ©æ‰‹"):
    with gr.Tab("çŸ¥è¯†åº“é—®ç­”"):
        with gr.Row():
            with gr.Column():
                msg = gr.Textbox(lines=2,placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ˆæ—…æ¸¸æ™¯ç‚¹ã€æ´»åŠ¨ã€é¤é¥®ã€ä½å®¿ã€è´­ç‰©ã€æ¨èè¡Œç¨‹ã€å°è´´å£«ç­‰å®ç”¨ä¿¡æ¯ï¼‰",label="æä¾›æ™¯ç‚¹æ¨èã€æ´»åŠ¨å®‰æ’ã€é¤é¥®ã€ä½å®¿ã€è´­ç‰©ã€è¡Œç¨‹æ¨èã€å®ç”¨å°è´´å£«ç­‰å®ç”¨ä¿¡æ¯")
                with gr.Row():
                    whether_rag = gr.Radio(choices=['æ˜¯','å¦'], value='å¦', label='æ˜¯å¦å¯ç”¨RAG')
                with gr.Row():
                    submit_button = gr.Button("å‘é€", elem_id="button")
                    clear_button = gr.Button("æ¸…é™¤å¯¹è¯", elem_id="button")
        
                # é—®é¢˜æ ·ä¾‹
                gr.Examples(["æˆ‘æƒ³å»é¦™æ¸¯ç©ï¼Œä½ æœ‰ä»€ä¹ˆæ¨èçš„å—ï¼Ÿ","åœ¨æ­å·ï¼Œå“ªäº›å®¶é¤é¦†å¯ä»¥æ¨èå»çš„ï¼Ÿ","æˆ‘è®¡åˆ’æš‘å‡å¸¦å®¶äººå»äº‘å—æ—…æ¸¸ï¼Œè¯·é—®æœ‰å“ªäº›å¿…æ¸¸çš„è‡ªç„¶é£å…‰å’Œæ°‘æ—æ–‡åŒ–æ™¯ç‚¹ï¼Ÿ","ä¸‹ä¸ªæœˆæˆ‘å°†åœ¨è¥¿å®‰ï¼Œæƒ³äº†è§£ç§¦å§‹çš‡å…µé©¬ä¿‘å¼€é€šæ—¶é—´ä»¥åŠäº¤é€šä¿¡æ¯","ç¬¬ä¸€æ¬¡å»è¥¿è—æ—…æ¸¸ï¼Œéœ€è¦æ³¨æ„å“ªäº›é«˜åŸååº”çš„é¢„é˜²æªæ–½ï¼Ÿ","å»ä¸‰äºšåº¦å‡ï¼Œæƒ³è¦ä½æµ·æ™¯é…’åº—ï¼Œæ€§ä»·æ¯”é«˜çš„é€‰æ‹©æœ‰å“ªäº›ï¼Ÿ","å»æ¾³é—¨æ—…æ¸¸çš„æœ€ä½³æ—¶é—´æ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿ","è®¡åˆ’ä¸€æ¬¡äº”å¤©å››å¤œçš„è¥¿å®‰æ·±åº¦æ¸¸ï¼Œæ€æ ·å®‰æ’è¡Œç¨‹æ¯”è¾ƒåˆç†ï¼Œèƒ½è¦†ç›–ä¸»è¦æ™¯ç‚¹ï¼Ÿ"], msg)
        
            with gr.Column():
                chatbot = gr.Chatbot(label="èŠå¤©è®°å½•",height=521)
    submit_button.click(respond, [msg, chatbot, whether_rag], [msg, chatbot])
    clear_button.click(clear_chat, chatbot, chatbot)        

    def weather_process(location):
        api_key = Weather_APP_KEY  # æ›¿æ¢æˆä½ çš„APIå¯†é’¥
        location_data = get_location_data(location, api_key)

        # å…œåº•åŸå¸‚åï¼ˆç”¨äºä¸‹æ¸¸ç©¿æ­ï¼‰
        city_name = (location or "").strip()

        # --- åŸæœ‰ï¼šå–åŸå¸‚ID ---
        if not location_data:
            # è¿”å›ï¼šHTMLè¯´æ˜, æ¸©åº¦(None), ç°è±¡(""), åŸå¸‚("")
            return "<div style='color:#c00'>æ— æ³•è·å–åŸå¸‚ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥æ‚¨çš„è¾“å…¥ã€‚</div>", None, "", ""

        loc0 = (location_data.get('location') or [{}])[0]
        location_id = loc0.get('id')
        city_name = loc0.get('name') or city_name

        if not location_id:
            return "<div style='color:#c00'>æ— æ³•ä»åŸå¸‚ä¿¡æ¯ä¸­è·å–IDã€‚</div>", None, "", city_name

        # --- åŸæœ‰ï¼šå–7å¤©é¢„æŠ¥ ---
        weather_data = get_weather_forecast(location_id, api_key)
        if not weather_data or weather_data.get('code') != '200':
            return "<div style='color:#c00'>æ— æ³•è·å–å¤©æ°”é¢„æŠ¥ï¼Œè¯·æ£€æŸ¥æ‚¨çš„è¾“å…¥å’ŒAPIå¯†é’¥ã€‚</div>", None, "", city_name

        # --- åŸæœ‰ï¼šæ„å»ºHTMLè¡¨æ ¼ ---
        html_content = "<table>"
        html_content += "<tr>"
        html_content += "<th>é¢„æŠ¥æ—¥æœŸ</th>"
        html_content += "<th>ç™½å¤©å¤©æ°”</th>"
        html_content += "<th>å¤œé—´å¤©æ°”</th>"
        html_content += "<th>æœ€é«˜æ¸©åº¦</th>"
        html_content += "<th>æœ€ä½æ¸©åº¦</th>"
        html_content += "<th>ç™½å¤©é£å‘</th>"
        html_content += "<th>ç™½å¤©é£åŠ›ç­‰çº§</th>"
        html_content += "<th>ç™½å¤©é£é€Ÿ</th>"
        html_content += "<th>å¤œé—´é£å‘</th>"
        html_content += "<th>å¤œé—´é£åŠ›ç­‰çº§</th>"
        html_content += "<th>å¤œé—´é£é€Ÿ</th>"
        html_content += "<th>æ€»é™æ°´é‡</th>"
        html_content += "<th>ç´«å¤–çº¿å¼ºåº¦</th>"
        html_content += "<th>ç›¸å¯¹æ¹¿åº¦</th>"
        html_content += "</tr>"

        daily_list = weather_data.get('daily', []) or []
        for day in daily_list:
            html_content += f"<tr>"
            html_content += f"<td>{day.get('fxDate', '')}</td>"
            html_content += f"<td>{day.get('textDay', '')} ({day.get('iconDay', '')})</td>"
            html_content += f"<td>{day.get('textNight', '')} ({day.get('iconNight', '')})</td>"
            html_content += f"<td>{day.get('tempMax', '')}Â°C</td>"
            html_content += f"<td>{day.get('tempMin', '')}Â°C</td>"
            html_content += f"<td>{day.get('windDirDay', 'æœªçŸ¥')}</td>"
            html_content += f"<td>{day.get('windScaleDay', 'æœªçŸ¥')}</td>"
            html_content += f"<td>{day.get('windSpeedDay', 'æœªçŸ¥')} km/h</td>"
            html_content += f"<td>{day.get('windDirNight', 'æœªçŸ¥')}</td>"
            html_content += f"<td>{day.get('windScaleNight', 'æœªçŸ¥')}</td>"
            html_content += f"<td>{day.get('windSpeedNight', 'æœªçŸ¥')} km/h</td>"
            html_content += f"<td>{day.get('precip', 'æœªçŸ¥')} mm</td>"
            html_content += f"<td>{day.get('uvIndex', 'æœªçŸ¥')}</td>"
            html_content += f"<td>{day.get('humidity', 'æœªçŸ¥')}%</td>"
            html_content += "</tr>"
        html_content += "</table>"

        # --- æ–°å¢ï¼šä¸ºâ€œç©¿æ­â€å‡†å¤‡ç»“æ„åŒ–å¤©æ°”ï¼ˆå½“å¤©ï¼‰ ---
        # å–åˆ—è¡¨ç¬¬ä¸€å¤©ä¸ºâ€œå½“å‰/æœ€è¿‘â€çš„å‚è€ƒï¼›ä¹Ÿå¯ä»¥ç²¾ç¡®åŒ¹é…ä»Šå¤©æ—¥æœŸ
        today = daily_list[0] if daily_list else {}
        # æ¸©åº¦ï¼šå–æœ€é«˜/æœ€ä½çš„å‡å€¼ä½œä¸ºç©¿æ­å‚è€ƒæ¸©åº¦
        temp_for_outfit = None
        try:
            tmax = float(today.get('tempMax'))
            tmin = float(today.get('tempMin'))
            temp_for_outfit = round((tmax + tmin) / 2.0, 1)
        except Exception:
            pass
        # å¤©æ°”ç°è±¡ä¼˜å…ˆç™½å¤©ï¼Œæ²¡æœ‰åˆ™ç”¨å¤œé—´
        cond_for_outfit = (today.get('textDay') or today.get('textNight') or "").strip()

        # è¿”å› 4 ä¸ªå€¼ï¼šHTMLå­—ç¬¦ä¸²ã€æ¸©åº¦ã€ç°è±¡ã€åŸå¸‚
        return html_content, temp_for_outfit, cond_for_outfit, city_name


    def clear_history_audio(history):
        history.clear()
        return history

    def clear_chat_audio(chat_history):
        return clear_history_audio(chat_history)

    with gr.Tab("å¤©æ°”æŸ¥è¯¢&é…’åº—é¤é¥®æœç´¢"):
        
        with gr.Row():
            with gr.Column():
                query_near = gr.Textbox(label="æŸ¥è¯¢é™„è¿‘çš„é¤é¥®ã€é…’åº—ç­‰", placeholder="ä¾‹å¦‚ï¼šåˆè‚¥å¸‚é«˜æ–°åŒºä¸­å›½å£°è°·äº§ä¸šå›­é™„è¿‘çš„ç¾é£Ÿ")
                result = gr.Textbox(label="æŸ¥è¯¢ç»“æœ", lines=2)
                submit_btn = gr.Button("æŸ¥è¯¢é™„è¿‘çš„é¤é¥®ã€é…’åº—ç­‰",elem_id="button")
                gr.Examples(["åˆè‚¥å¸‚é«˜æ–°åŒºä¸­å›½å£°è°·äº§ä¸šå›­é™„è¿‘çš„ç¾é£Ÿ", "åŒ—äº¬ä¸‰é‡Œå±¯é™„è¿‘çš„å’–å•¡", "å—äº¬å¸‚ç„æ­¦åŒºæ–°è¡—å£é™„è¿‘çš„ç”œå“åº—", "ä¸Šæµ·æµ¦ä¸œæ–°åŒºé™†å®¶å˜´é™„è¿‘çš„çƒ­é—¨é¤å…", "æ­¦æ±‰å¸‚å…‰è°·æ­¥è¡Œè¡—é™„è¿‘çš„ç«é”…åº—", "å¹¿å·å¸‚å¤©æ²³åŒºç æ±Ÿæ–°åŸé™„è¿‘çš„é…’åº—"], query_near)

                # ç»“æœå¯è§†åŒ–åŒºåŸŸï¼ˆå°±åœ¨ result ä¸‹é¢åŠ ï¼‰
                # nearby_cards_html = gr.HTML(label="ç»“æœå¯è§†åŒ–å±•ç¤º")

                # ç»§ç»­ä¿ç•™ä½ åŸæ¥çš„æ–‡æœ¬ç»“æœï¼š
                submit_btn.click(process_request, inputs=[query_near], outputs=[result])

            with gr.Column():
                query_network = gr.Textbox(label="è”ç½‘æœç´¢é—®é¢˜", placeholder="ä¾‹å¦‚ï¼šç§¦å§‹çš‡å…µé©¬ä¿‘å¼€æ”¾æ—¶é—´")
                result_network = gr.Textbox(label="æœç´¢ç»“æœ", lines=2)
                cards_html = gr.HTML(label="ç›¸å…³å›¾æ–‡å¡ç‰‡")


                # submit_btn_network = gr.Button("è”ç½‘æœç´¢",elem_id="button")
                btn_aiq = gr.Button("ç”¨ AIQ è”ç½‘æœç´¢", elem_id="button")
                gr.Examples(["ç§¦å§‹çš‡å…µé©¬ä¿‘å¼€æ”¾æ—¶é—´", "åˆè‚¥æœ‰å“ªäº›ç¾é£Ÿ", "åŒ—äº¬æ•…å®«å¼€æ”¾æ—¶é—´", "é»„å±±æ™¯ç‚¹ä»‹ç»", "ä¸Šæµ·è¿ªå£«å°¼é—¨ç¥¨éœ€è¦å¤šå°‘é’±"], query_network)
                # evt_net = submit_btn_network.click(process_network, inputs=[query_network], outputs=[result_network])
                # evt_net.then(
                #     fn=build_info_cards,
                #     inputs=[query_network, result_network],   # è¿™é‡Œæˆ‘ä¹ŸæŠŠæœç´¢ç»“æœä¼ è¿›æ¥ï¼Œåç»­ä½ æƒ³ç”¨ä¹Ÿæœ‰
                #     outputs=[cards_html]
                # )

                aiq_cfg_state = gr.State(AIQ_WORKFLOW_CFG)

                # åªæŠŠæ–‡æœ¬ç»“æœå†™å›â€œæœç´¢ç»“æœâ€ï¼›å¦‚æœä½ æœ‰ cards_htmlï¼Œå¯ä¸€å¹¶è¾“å‡º
                evt_net = btn_aiq.click(
                    fn=process_network_aiq,
                    inputs=[query_network, aiq_cfg_state],
                    outputs=[result_network]           # å¦‚æœè¦è¿å¸¦å¡ç‰‡ï¼šoutputs=[result_network, cards_html]
                )
                evt_net.then(
                    fn=build_info_cards,
                    inputs=[query_network, result_network],   # è¿™é‡Œæˆ‘ä¹ŸæŠŠæœç´¢ç»“æœä¼ è¿›æ¥ï¼Œåç»­ä½ æƒ³ç”¨ä¹Ÿæœ‰
                    outputs=[cards_html]
                )

        weather_input = gr.Textbox(label="è¯·è¾“å…¥åŸå¸‚åæŸ¥è¯¢å¤©æ°”", placeholder="ä¾‹å¦‚ï¼šåŒ—äº¬")
        weather_output = gr.HTML(value="", label="å¤©æ°”æŸ¥è¯¢ç»“æœ")
        # â• æ–°å¢ï¼šæ‰¿æ¥åŸå¸‚/æ¸©åº¦/å¤©æ°”ç°è±¡
        w_city_state = gr.State()   # str
        w_temp_state = gr.State()   # float
        w_cond_state = gr.State()   # str
        query_button = gr.Button("æŸ¥è¯¢å¤©æ°”",elem_id="button")
        query_button.click(
            weather_process,
            inputs=[weather_input],
            outputs=[weather_output, w_temp_state, w_cond_state, w_city_state]
        )

        with gr.Row():
            outfit_btn = gr.Button("åŸºäºå½“å‰å¤©æ°”ç”Ÿæˆç©¿æ­å›¾", variant="primary")
        with gr.Row():
            men_gallery   = gr.Gallery(label="ç”·å£«ç©¿æ­", columns=4, rows=2, height=420, interactive=False)
            women_gallery = gr.Gallery(label="å¥³å£«ç©¿æ­", columns=4, rows=2, height=420, interactive=False)
        outfit_note = gr.Markdown("")   # å±•ç¤ºæ‘˜è¦ä¸æ£€ç´¢è¯

        def gen_outfit_from_weather_state(w_city, w_temp, w_cond, fallback_city):
            city = (w_city or fallback_city or "ä¸Šæµ·").strip()
            if w_temp is None or not w_cond:
                return [], [], f"âš ï¸ è¯·å…ˆæŸ¥è¯¢å¤©æ°”åå†ç”Ÿæˆç©¿æ­å›¾ã€‚"

            men, women, summary, mq, wq = outfit_reco_by_weather(float(w_temp), str(w_cond), city=city)
            if not men and not women:
                return [], [], f"âš ï¸ æœªè·å–åˆ°ç©¿æ­å›¾ç‰‡ï¼š{city} {w_temp}â„ƒ Â· {w_cond}\n\næ£€ç´¢ï¼š`{mq}` / `{wq}`"
            note = f"**{city} Â· {w_temp:.0f}â„ƒ Â· {w_cond}**\n\nç”·æ¬¾æ£€ç´¢ï¼š`{mq}`\n\nå¥³æ¬¾æ£€ç´¢ï¼š`{wq}`"
            return men, women, note

        outfit_btn.click(
            fn=gen_outfit_from_weather_state,
            inputs=[w_city_state, w_temp_state, w_cond_state, weather_input],  # fallback åŸå¸‚ç”¨è¾“å…¥æ¡†
            outputs=[men_gallery, women_gallery, outfit_note]
        )
        
if __name__ == "__main__":
    demo.queue().launch(share=True)